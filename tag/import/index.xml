<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>import | Michael&#39;s Site</title>
    <link>https://dmsenter89.github.io/tag/import/</link>
      <atom:link href="https://dmsenter89.github.io/tag/import/index.xml" rel="self" type="application/rss+xml" />
    <description>import</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Mon, 01 Aug 2022 17:21:38 -0400</lastBuildDate>
    <image>
      <url>https://dmsenter89.github.io/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png</url>
      <title>import</title>
      <link>https://dmsenter89.github.io/tag/import/</link>
    </image>
    
    <item>
      <title>Loading Zillow Housing Data in SAS</title>
      <link>https://dmsenter89.github.io/post/22-08-zillow-data/</link>
      <pubDate>Mon, 01 Aug 2022 17:21:38 -0400</pubDate>
      <guid>https://dmsenter89.github.io/post/22-08-zillow-data/</guid>
      <description>&lt;p&gt;Zillow is a well-known website widely used by those searching for a home or curious to find out
the value of their current home. What you may not know is that Zillow has a dedicated research page.
To make their website work optimally, they churn through tons of data on the American housing market.
They share insights they gleaned via 
&lt;a href=&#34;https://www.zillow.com/research/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;zillow.com/research&lt;/a&gt;. If you
visit their research  website you&amp;rsquo;ll notice they have a data page where you can download some really
cool data sets for your own research. They even have an API with which you can load data directly, but
you&amp;rsquo;ll have to register for access. In this post, we&amp;rsquo;ll look at how to load the CSV files that are
available for direct download into SAS for analysis.&lt;/p&gt;
&lt;p&gt;The CSV files can be downloaded 
&lt;a href=&#34;https://www.zillow.com/research/data/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;. In the example below,
I&amp;rsquo;m working with the Zillow Home Value Index file for all homes, seasonally adjusted at the ZIP code level.
Tha file is fairly large. It has data going from January 2000 through June 2022 in more than 27,000 rows of data
and about 280 columns. Below is an image of the beginning of this file.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;zhvi_data_preview.png&#34; alt=&#34;&#34; title=&#34;The beginning of the of the ZHVI &#39;flagship&#39; data file.&#34;&gt;&lt;/p&gt;
&lt;p&gt;When working with large CSV files, I find it useful to get a feel for it in the CLI with

&lt;a href=&#34;https://csvkit.readthedocs.io/en/latest/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;csvkit&lt;/a&gt;. This is especially important when importing
with a SAS data step, because we need to know the number of columns and their order, amongst other things,
for our code. To get an overview of the total number of columns and their contents, run&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;csvcut -n Zip_zhvi_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The output is fairly long, so you may prefer piping to a pager. I don&amp;rsquo;t need all the different identifiers
in the file, so I&amp;rsquo;m going to exclude those I won&amp;rsquo;t need and put them into a separate, smaller CSV.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# ignore these four columns which I won&#39;t need
csvcut -C RegionID,SizeRank,RegionType,StateName Zip_zhvi_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv &amp;gt; Zip_zhvi_small.csv
# alternatively, also cut down on date columns to only 2022 for debugging 
csvcut -C RegionID,SizeRank,RegionType,StateName,10-273 Zip_zhvi_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv &amp;gt; Zip_zhvi_small.csv
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can also reduce the file size by using &lt;code&gt;csvgrep&lt;/code&gt; to filter any of the columns. For example, if we only wanted
the data for North Carolina we could run &lt;code&gt;csvgrep -c State -m NC&lt;/code&gt; in the pipe.&lt;/p&gt;
&lt;p&gt;For SAS, we need to know the maximum length of string columns so we can allocate the appropriate length to the
corresponding SAS variables. This is easily done with the csvstat tool:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;csvcut -c Metro,City,CountyName Zip_zhvi_small.csv | csvstat --len
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can also specify the list of columns in csvstat directly, but in my experience that tends to be slower.&lt;/p&gt;
&lt;p&gt;Alright, now we have everything we need to start on our DATA step! We start with the attribute statement.
One problem with importing this file is that everyhing is in wide format, with the dates used as headers.
We will get around this shortly. I have seen people use transpose etc for similar problems online, but this
is unnecessary if we feel comfortable with the DATA step. We&amp;rsquo;ll start by naming the identifying columns
just as in the CSV file. For the date columns, we will use a numeric range prefixed by date (&lt;code&gt;date1-date270&lt;/code&gt;).
You can use csvcut to find the exact number of date columns you have. We will also allocate the same number of
columns for the ZHVI values, so we&amp;rsquo;ll need to add a &lt;code&gt;val1-val270&lt;/code&gt;. This and the date variable are temporary
and will be dropped later, in favor of the &lt;code&gt;Date&lt;/code&gt; and &lt;code&gt;ZHVI&lt;/code&gt; variables.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-SAS&#34;&gt;attrib 
    ZIP           informat=best12.    format=z5.
    State         informat=$2.
    City          informat=$30.
    Metro         informat=$42.
    CountyName    informat=$29.
    date1-date270 informat=YYMMDD10.  format=DATE9.
    val1-val270   informat=best16.
    Date                              format=Date9.
    ZHVI                              format=Dollar16.
  ;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we will allocate an array to hold &lt;em&gt;all&lt;/em&gt; of the date and ZHVI values during the processing of each row.
Since the date column won&amp;rsquo;t change, we&amp;rsquo;ll tell SAS to retain its values.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-SAS&#34;&gt;   retain date1-date270;
   array d(270) date1-date270;
   array v(270) val1-val270;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is where the magic happens now. You may not know it, but you are not limited to a single INPUT statement
in a DATA step. We use this and start by reading in only the first row. Because we use an OUTPUT
statement later, this reading of row 1 will be processed, but not saved into the output data set.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-SAS&#34;&gt;if _n_ = 1 then do;
  input ZIP $ State $ City $ Metro $ CountyName $ date1-date270;
  PUT _ALL_; /* if you want to see what that looks like */
end;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With this if clause, the date1 through date270 variables will be populated, and because we used a retain
statement earlier, these values remain available to us during the processing of every other row. You can
probably guess where this is going now: we will process each row, and then OUTPUT one line per date which
we have access to now thanks to our array and the retain statement.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-SAS&#34;&gt;input ZIP $ State $ City $ Metro $ CountyName $ val1-val270;
do i=1 to 270;
  Date  = d(i); /* look up date for column i */
  ZHVI =  v(i); /* use the corresponding i-th value for ZHVI */
  OUTPUT;       /* This output creates one line per date column */
end;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;At the end of your data step, don&amp;rsquo;t forget to&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-SAS&#34;&gt;drop i date1-date270 val1-val270;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;so those variables don&amp;rsquo;t clutter your data set. And that&amp;rsquo;s it! You now
have the data set loaded and available in SAS.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;SAS_data_set.png&#34; alt=&#34;&#34; title=&#34;The beginning of the resulting SAS data set.&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>From Proc Import to a Data Step with Regex</title>
      <link>https://dmsenter89.github.io/post/21-07-proc-import-to-data-step-with-regex/</link>
      <pubDate>Thu, 29 Jul 2021 08:46:10 -0400</pubDate>
      <guid>https://dmsenter89.github.io/post/21-07-proc-import-to-data-step-with-regex/</guid>
      <description>&lt;p&gt;I find myself needing to import CSV files with a relatively large number of columns. In many cases, &lt;code&gt;proc import&lt;/code&gt; works surprisingly well in giving me what I want. But sometimes, I need to do some work while reading in the file and it would be nice to just use a data step to do so, but I don&amp;rsquo;t want to type it in by hand. That&amp;rsquo;s when a combination of &lt;code&gt;proc import&lt;/code&gt; and some regex substitution can come in handy.&lt;/p&gt;
&lt;p&gt;For the first step, run a &lt;code&gt;proc import&lt;/code&gt;, like this sample code that is provided by SAS Studio when you double click on a CSV file:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sas&#34;&gt;FILENAME REFFILE &#39;/path/to/file/data.csv&#39;;

PROC IMPORT DATAFILE=REFFILE
    DBMS=CSV
    OUT=WORK.IMPORT;
    GETNAMES=YES;
RUN;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you run this code, you will see that SAS generates a complete data step for you. This is what the beginning of one looks like:&lt;/p&gt;





  
  











&lt;figure id=&#34;figure-sample-log-output&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://dmsenter89.github.io/post/21-07-proc-import-to-data-step-with-regex/log_hu417e5750fec5319adb043ca92305efb0_26856_2000x2000_fit_lanczos_2.PNG&#34; data-caption=&#34;Sample log output.&#34;&gt;


  &lt;img data-src=&#34;https://dmsenter89.github.io/post/21-07-proc-import-to-data-step-with-regex/log_hu417e5750fec5319adb043ca92305efb0_26856_2000x2000_fit_lanczos_2.PNG&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;797&#34; height=&#34;461&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Sample log output.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;There will be be two lines for each variable, one giving the &lt;code&gt;informat&lt;/code&gt; and one giving the &lt;code&gt;format&lt;/code&gt; that SAS decided on. This will be followed by an &lt;code&gt;input&lt;/code&gt; statement. You can copy that from the log into a text editor such as VSCode, but unfortunately the line numbering of the LOG will carry over. One convenient way of fixing this is to use regex search-and-replace. Each line starts with a space followed by 1-3 digits, followed by a variable number of spaces until the next word. To capture this I use &lt;code&gt;^\s\d{1,3}\s+&lt;/code&gt; as my search term and replace with nothing. This will left align the whole data step, but this can be adjusted later.&lt;/p&gt;
&lt;p&gt;At this point the data step can be saved as a SAS file or copied back over to the file you are working within SAS Studio, but I like to do one more adjustment. I really like using the &lt;code&gt;attrib&lt;/code&gt; statement, 
&lt;a href=&#34;https://documentation.sas.com/doc/en/pgmsascdc/9.4_3.5/lestmtsref/n1wxb7p9jkxycin16lz2db7idbnt.htm&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;see documentation&lt;/a&gt;, because it allows me to see the informat, format, and label of a variable all in one place. So I use regex to re-arrange my informat statement into the beginnings of an attribute statement. Use the search term &lt;code&gt;informat\s([^\s]+)\s([^\s]+)\s+;&lt;/code&gt; to capture each informat line and create two capture groups - the variable name as group 1 and the informat as group 2. If you use the replace code &lt;code&gt;$1 informat=$2 format=$2&lt;/code&gt;, you will see the beginnings of an attribute statement. In this replacement scheme, each informat matches each format. This is fine for date and character variables, but you may want to adjust the display format for some of your numeric variables.&lt;/p&gt;
&lt;p&gt;To clean this up, get rid of the format lines (you can search for &lt;code&gt;^format.+\n&lt;/code&gt; and replace with an empty replace to delete them), add the &lt;code&gt;attrib&lt;/code&gt; statement below the &lt;code&gt;infile&lt;/code&gt; and make sure to end the block of attributes with a semicolon, and indent your code as desired.&lt;/p&gt;





  
  











&lt;figure id=&#34;figure-sample-data-step-view&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://dmsenter89.github.io/post/21-07-proc-import-to-data-step-with-regex/code_snip_hub5c78044ade6674b35a08b503d783f3d_19917_2000x2000_fit_lanczos_2.PNG&#34; data-caption=&#34;Sample data step view.&#34;&gt;


  &lt;img data-src=&#34;https://dmsenter89.github.io/post/21-07-proc-import-to-data-step-with-regex/code_snip_hub5c78044ade6674b35a08b503d783f3d_19917_2000x2000_fit_lanczos_2.PNG&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;843&#34; height=&#34;190&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Sample data step view.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;And there you have it! The beginning of a nicely formatted data step that you can start to work with.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
