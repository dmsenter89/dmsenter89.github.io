<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>simulation | Michael&#39;s Site</title>
    <link>https://dmsenter89.github.io/tag/simulation/</link>
      <atom:link href="https://dmsenter89.github.io/tag/simulation/index.xml" rel="self" type="application/rss+xml" />
    <description>simulation</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Tue, 03 Jan 2023 10:00:00 -0500</lastBuildDate>
    <image>
      <url>https://dmsenter89.github.io/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png</url>
      <title>simulation</title>
      <link>https://dmsenter89.github.io/tag/simulation/</link>
    </image>
    
    <item>
      <title>Missing Data Mechanisms</title>
      <link>https://dmsenter89.github.io/post/23-01-missing-data-mechanisms/</link>
      <pubDate>Tue, 03 Jan 2023 10:00:00 -0500</pubDate>
      <guid>https://dmsenter89.github.io/post/23-01-missing-data-mechanisms/</guid>
      <description>&lt;p&gt;Understanding whether a variable&amp;rsquo;s missingness from a dataset is related to the underlying value of the data is a key concept in the field of missing data analysis. We distinguish three broad categories: missing completely at random (MCAR), missing at random (MAR), and missing not at random (MNAR). In his book &lt;em&gt;Statistical Rethinking&lt;/em&gt;, McElreath&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; gives an amusing example to illustrate this concept: he considers variants of a dog eating homework and how the dog chooses - if at all - to eat the homework. The examples he give show substantial shifts in observed values, which make for a good illustration of the types of problems you might encounter. A lecture corresponding to the  example from the book can be found on 
&lt;a href=&#34;https://www.youtube.com/watch?v=oMiSb8GKR0o&amp;amp;list=PLDcUM9US4XdMROZ57-OIRtIK0aOynbgZN&amp;amp;index=18&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;YouTube&lt;/a&gt;. In this post, I will first briefly review the different missing data mechanisms before implementing McElreath&amp;rsquo;s examples in SAS.&lt;/p&gt;
&lt;h3 id=&#34;overview-of-missing-data-mechanisms&#34;&gt;Overview of Missing Data Mechanisms&lt;/h3&gt;
&lt;p&gt;My presentation here follows van Buuren&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;. Let $Y$ be a $n \times p$ matrix representing a sample of $p$ variables for $n$ units of the sample and $R$ be a corresponding $n \times p$ indicator matrix, so that&lt;/p&gt;
&lt;p&gt;$$r_{i,j} = \begin{cases} 1 &amp;amp; y_{i,j} \text{ is observed} \\ 0 &amp;amp; y_{i,j} \text{ not observed.}\end{cases} $$&lt;/p&gt;
&lt;p&gt;We denote the observed data by $Y_\text{obs}$ and the missing data that $Y_\text{miss}$ so that $Y=(Y_\text{obs},Y_\text{miss})$.&lt;/p&gt;
&lt;p&gt;We distinguish three main categories for how the distribution of $R$ may depend on $Y$. This relationship is described as the &lt;em&gt;missing data model&lt;/em&gt;. Let $\psi$ contain the parameters of this model. The general expression of the missing data model is $\mathrm{Pr}(R|Y_\text{obs}, Y_\text{miss}, \psi)$, where $\psi$ consists of the parameters of the missing data model.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Missing Completely at Random (MCAR).&lt;/strong&gt; This implies that the cause of the missing data is unrelated to the data itself. In this case,&lt;/p&gt;
&lt;p&gt;$$ \mathrm{Pr}(R=0| Y_\text{obs}, Y_\text{miss}, \psi) = \mathrm{Pr}(R=0|\psi).$$&lt;/p&gt;
&lt;p&gt;This is the ideal case, but unfortunately rare in practice. Many researchers implicitly assume this when using methods such as list-wise deletion, otherwise known as complete case analysis, which can produce unbiased estimates of sample means if the data are MCAR, although the reported standard error will be too large.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Missing at Random (MAR).&lt;/strong&gt; Missingness is the same within groups defined by the observed data, so that&lt;/p&gt;
&lt;p&gt;$$ \mathrm{Pr}(R=0| Y_\text{obs}, Y_\text{miss}, \psi) = \mathrm{Pr}(R=0|Y_\text{obs},\psi).$$&lt;/p&gt;
&lt;p&gt;This is a often a more reasonable assumption in practice and the starting point for modern missing data methods.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Missing not at Random (MNAR).&lt;/strong&gt; If neither the MCAR or MAR assumptions hold, then we may find that missingness depends on the missing data itself, in which case there is no simplification and
$$ \mathrm{Pr}(R=0| Y_\text{obs}, Y_\text{miss}, \psi) = \mathrm{Pr}(R=0| Y_\text{obs}, Y_\text{miss}, \psi).$$&lt;/p&gt;
&lt;p&gt;As you can imagine, this is the most tricky case to deal with.&lt;/p&gt;
&lt;h3 id=&#34;dogs-eating-homework&#34;&gt;Dogs Eating Homework&lt;/h3&gt;
&lt;p&gt;Consider dogs (D) eating students&#39; homework. Each student&amp;rsquo;s homework score (H) is graded on a 10-point scale and each student&amp;rsquo;s score varies in proportion to how much they study (S). We assume the amount of time they study is normally distributed. A binomial is used to generate homework scores from the normed time spent studying. McElreath uses the following code to simulate the full data set:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-R&#34;&gt;N &amp;lt;- 100
S &amp;lt;- rnorm( N )
H &amp;lt;- rbinom( N, size=10, inv_logit(S) )
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;where &lt;code&gt;inv_logit(x) = exp(x)+(1+exp(x))&lt;/code&gt;, the definition used by the &lt;code&gt;LOGISTIC&lt;/code&gt; function in SAS. With a data step, this can be represented in SAS as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sas&#34;&gt;data full;
    DO i=1 to 100;
        S=RAND(&#39;NORM&#39;);
        H=RAND(&#39;BINO&#39;, LOGISTIC(S), 10);
        output;
    END;
    label S=&#39;Amount of Studying&#39; H=&#39;Homework Score&#39;;
    drop i;
run;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can get closer in form to the R code by using PROC IML, but that&amp;rsquo;s a story for a different post.&lt;/p&gt;
&lt;p&gt;Say we are interested in estimating the relationship between $S$ and $H$. In our example, we assume that $H$ is not directly observable. Instead, $H^*$ is observed - a subset of the full data set $H$ with some homework values missing. We can now look at &lt;em&gt;why&lt;/em&gt; some of those values are missing. Specifically, in McElreath&amp;rsquo;s example each student has a dog $D$ and sometimes the dog eats the homework. But here we can again ask, why is the dog eating the homework? McElreath uses  
&lt;a href=&#34;https://en.wikipedia.org/wiki/Directed_acyclic_graph&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;directed acyclic graphs&lt;/a&gt; (DAGs) to represent different missing data models, reproduced below. As we will see, these are some intuitive examples for our three missing data mechanism categories.&lt;/p&gt;





  
  











&lt;figure id=&#34;figure-the-directed-acyclic-graphs-corresponding-to-mcelreaths-examples-of-missing-data-models-s-represents-the-amount-of-time-spent-studying-which-in-turn-influences-the-homework-score-h-which-is-only-partially-observed-indicated-by-the-circle-alas-dogs-d-eat-some-of-the-homework-the-actually-observed-scores---those-not-eaten---are-indicated-by-h-adapted-from-figure-154-in-_statistical-rehinking_&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://dmsenter89.github.io/post/23-01-missing-data-mechanisms/dag_hu9d4aa2d4b53fa51c30ec3b81dc4e20f1_14343_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;The directed acyclic graphs corresponding to McElreath&amp;amp;rsquo;s examples of missing data models. $S$ represents the amount of time spent studying, which in turn influences the homework score $H$, which is only partially observed (indicated by the circle). Alas, dogs $D$ eat some of the homework. The actually observed scores - those not eaten - are indicated by $H^*$. Adapted from figure 15.4 in &amp;lt;em&amp;gt;Statistical Rehinking&amp;lt;/em&amp;gt;.&#34;&gt;


  &lt;img data-src=&#34;https://dmsenter89.github.io/post/23-01-missing-data-mechanisms/dag_hu9d4aa2d4b53fa51c30ec3b81dc4e20f1_14343_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;665&#34; height=&#34;179&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; class=&#34;numbered&#34;&gt;
    The directed acyclic graphs corresponding to McElreath&amp;rsquo;s examples of missing data models. $S$ represents the amount of time spent studying, which in turn influences the homework score $H$, which is only partially observed (indicated by the circle). Alas, dogs $D$ eat some of the homework. The actually observed scores - those not eaten - are indicated by $H^*$. Adapted from figure 15.4 in &lt;em&gt;Statistical Rehinking&lt;/em&gt;.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h4 id=&#34;missing-completely-at-random-mcar&#34;&gt;Missing Completely At Random (MCAR)&lt;/h4&gt;
&lt;p&gt;In the first example, the dogs eat homework completely at random. This is the most basic and benign case, and corresponds to DAG 1) in Figure 1. McElreath&amp;rsquo;s R code is given by&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-R&#34;&gt;D &amp;lt;- rbern( N ) 
Hm &amp;lt;- H  # H*, but * is not a valid char for varnames in R
Hm[D==1] &amp;lt;- NA
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can implement this in SAS by using the &lt;code&gt;RAND&lt;/code&gt; function with the Bernoulli argument in an if/else clause:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sas&#34;&gt;if RAND(&#39;BERN&#39;, 0.5) then Hm = .;
    else Hm = H;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This causes about half of our data to be hidden, but not in a biased way.&lt;/p&gt;
&lt;h4 id=&#34;missing-at-random-mar&#34;&gt;Missing at Random (MAR)&lt;/h4&gt;
&lt;p&gt;In the second example, we assume the amount of time a student spends studying decreases the amount of time they have to play with and exercise their dog. This, in turn, influences whether the homework gets eaten. Or, as McElreath puts it, the &amp;ldquo;dog eats conditional on the cause of homework.&amp;rdquo; In his particular example, the homework is eaten whenever a student spends more time studying than the average $S=0$. This corresponds to DAG 2) in Figure 1.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-R&#34;&gt;D &amp;lt;- ifelse( S&amp;gt;0 , 1 , 0 )
Hm &amp;lt;- H
Hm[D==1] &amp;lt;-NA
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In SAS:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sas&#34;&gt;if S&amp;gt;0 then Hm = .;
    else Hm = H;
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;missing-not-at-random-mnar&#34;&gt;Missing not at Random (MNAR)&lt;/h4&gt;
&lt;p&gt;In this case, we have some correspondence between the missing variable&amp;rsquo;s value and whether or not it is missing from the data set. Here, the &amp;ldquo;dog eats conditional on the homework itself.&amp;rdquo; Suppose that dogs prefer to eat bad homework. In such a case, the value of $H$ is directly related to whether or not $H$ is observed in the particular unit or not. His example R code is as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-R&#34;&gt;# dogs prefer bad homework
D &amp;lt;- ifelse( H&amp;lt;5 , 1 , 0 )
Hm &amp;lt;- H
Hm[D==1] &amp;lt;- NA
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And in SAS:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sas&#34;&gt;if H&amp;lt;5 then Hm = .;
    else Hm = H;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;the-full-sas-code&#34;&gt;The Full SAS Code&lt;/h3&gt;
&lt;p&gt;We can now build a SAS data set that contains a full copy of the original data set, together with our various examples of missing data mechanisms. I have added a seed to the data step for reproducibility.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sas&#34;&gt;data full;
    CALL streaminit( 451 ); 
    
    LABEL
        Type = &#39;Missing Data Mechanism&#39;
        S = &#39;Amount of Studying&#39;
        H = &#39;Homework Score&#39;
        Hm = &#39;Observed Homework Score&#39;
    ;

    DO i=1 to 100;
        TYPE = &#39;FULL&#39;;
        S = RAND(&#39;NORM&#39;);
        H = RAND(&#39;BINO&#39;, LOGISTIC(S), 10);
        Hm = H;
        output;
        
        /* Example 1) MCAR */
        TYPE = &#39;MCAR&#39;;
        if RAND(&#39;BERN&#39;, 0.5) then Hm = .;
            else Hm = H;
        output;
        
        /* Example 2) MAR */
        TYPE = &#39;MAR&#39;;
        if S&amp;gt;0 then Hm = .;
            else Hm = H;
        output;
        
        /* Example 3) MNAR */
        TYPE = &#39;MNAR&#39;;
        if H&amp;lt;5 then Hm = .;
            else Hm = H;
        output;
    
    END;
    
    drop i;
run;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You may want to run a &lt;code&gt;PROC SORT&lt;/code&gt; or &lt;code&gt;PROC SQL&lt;/code&gt; afterwards to group the different categories together, as they will be alternating in this data set.&lt;/p&gt;
&lt;h3 id=&#34;results&#34;&gt;Results&lt;/h3&gt;





  
  











&lt;figure id=&#34;figure-boxplot-of-our-example-data-note-that-the-mcar-data-looks-very-similar-to-the-original-data-set-unlike-the-mar-and-mnar-versions&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://dmsenter89.github.io/post/23-01-missing-data-mechanisms/mdm_boxplot_hu7d089ca360b9b11aaf1a482082b6d8dc_11177_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;Boxplot of our example data. Note that the MCAR data looks very similar to the original data set, unlike the MAR and MNAR versions.&#34;&gt;


  &lt;img data-src=&#34;https://dmsenter89.github.io/post/23-01-missing-data-mechanisms/mdm_boxplot_hu7d089ca360b9b11aaf1a482082b6d8dc_11177_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;640&#34; height=&#34;480&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; class=&#34;numbered&#34;&gt;
    Boxplot of our example data. Note that the MCAR data looks very similar to the original data set, unlike the MAR and MNAR versions.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;We can see that MCAR leads to minimal bias in our example data, while both the MAR and MNAR variations lead to substantial differences in observed vs actual homework scores for our synthetic population. For a more subtle example, see section 2.2.4 in van Buuren,&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt; available 
&lt;a href=&#34;https://stefvanbuuren.name/fimd/sec-idconcepts.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;online here&lt;/a&gt;.&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;R. McElreath, &lt;em&gt;Statistical Rethinking&lt;/em&gt;, 2nd ed, Chapman and Hall/CRC, Boca Raton, FL, 2020. &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;S. van Buuren, &lt;em&gt;Flexible Imputation of Missing Data&lt;/em&gt;, 2nd ed, Chapman and Hall/CRC, Boca Raton, FL, 2019. &lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
    <item>
      <title>Does it ever make sense to play the Lottery?</title>
      <link>https://dmsenter89.github.io/post/22-09-lottery/</link>
      <pubDate>Fri, 30 Sep 2022 15:40:00 -0400</pubDate>
      <guid>https://dmsenter89.github.io/post/22-09-lottery/</guid>
      <description>&lt;p&gt;In a first semester probability course, students encounter combinatorics and point estimates such as the mean and median of a data set. A common example is the low odds of winning the lottery. When discussing the topic of point estimates, students are exposed to the idea of a &amp;ldquo;fair bet&amp;rdquo; or &amp;ldquo;fair game&amp;rdquo; - one in which the expected value of the random variable associated with the game is equal to the cost of participation or zero, depending on if a fixed cost is included in the game or tracked separately. This year, the Mega Millions had a jackpot in excess of one billion dollars. This had me thinking - mathematically, this is likely a fair game. But I still would expect to loose out playing it. In this article, I want to explore this idea further using the Mega Millions lottery as a particular example.&lt;/p&gt;
&lt;p&gt;Mega Millions is played by a choosing five numbers from 1 to 70 (the white balls) and one number from 1 to 25 (the golden &amp;ldquo;Mega Ball&amp;rdquo;). Five white balls (W) and one golden ball (G) are drawn without replacement twice per week. Prizes are earned by matching the drawn numbers. Payouts generally follow a fixed schedule for everything but the jackpot, at least outside of California where the payouts for all prizes are pari-mutual instead. Below is a table of all possible events as given on the Mega Millions 
&lt;a href=&#34;https://www.megamillions.com/How-to-Play.aspx&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;website&lt;/a&gt;, sorted by increasing odds.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Event&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Variable&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Value&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Odds&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;5 W + G&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$x_1$&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Jackpot&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;1/302,575,350&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;5 W&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$x_2$&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$1,000,000&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;1/12,607,306&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;4 W + G&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$x_3$&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$10,000&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;1/931,001&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;4 W&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$x_4$&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$500&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;1/38,792&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;3 W + G&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$x_5$&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$200&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;1/14,547&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2 W + G&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$x_6$&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$10&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;1/693&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;3 W&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$x_7$&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$10&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;1/606&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1 W + G&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$x_8$&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$4&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;1/89&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;G&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$x_9$&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$2&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;1/37&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;No Match&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$x_{10}$&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$0&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;24/1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;the-fair-bet-analysis&#34;&gt;The Fair Bet Analysis&lt;/h2&gt;
&lt;p&gt;A Fair Bet or Fair game is one in which the expected value of the random variable doesn&amp;rsquo;t favor either the player or the house. Given a cost of 2 USD per game,
we can say that Mega Millions is fair when $E[X]=2$, or more specifically when&lt;/p&gt;
&lt;p&gt;$$E[X] = \sum_{i=1}^{10} x_i P(X=x_i) = \frac{n}{302,575,351}  + \sum_{i=2}^{10} x_i P(X=x_i) = 2$$&lt;/p&gt;
&lt;p&gt;I use Maxima to solve for the jackpot representing a fair game and to print a few representative values of the expected value for some jackpot options.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-maxima&#34;&gt;/* Define Expectation as dependent on n */
E(n) := n/302575351 + 1000000/12607307 + 10000/931002 + 
		500/38793 + 200/14548 +  10/694 + 10/607 + 4/90 + 2/38;
/* solve for fair game */
float(solve(E(n)=2,n));

/* give expected return for different jackpot values */
jackpots : [5e7, 1e8, 2.5e8, 5e8, 7.5e8, 1e9, 2e9];
for i in jackpots do printf(true, &amp;quot;E(~:D) = $~$ ~%&amp;quot;, i, E(i))$
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;From this we learn that to have a fair jackpot, we require $n = 531,123,698.80$. Even with a fair pet, the expected value is very modest. For example, a 2 billion USD jackpot has $E[X]~=6.85$ - less than 5 USD above the ticket price.&lt;/p&gt;
&lt;h2 id=&#34;how-long-until-we-profit&#34;&gt;How long until we Profit?&lt;/h2&gt;
&lt;p&gt;Most people don&amp;rsquo;t play the lottery to win small amounts like 5 USD. They want to become millionaires. Given that our expected values are so low, let&amp;rsquo;s take a look at how long it will take us to become rich if we take the lottery game route.&lt;/p&gt;
&lt;h3 id=&#34;the-geometric-distribution-and-our-lottery&#34;&gt;The Geometric Distribution and Our Lottery&lt;/h3&gt;
&lt;p&gt;Let&amp;rsquo;s start by considering only the events that would result in a win of a million dollars or more. In other words, events $x_1$ and $x_2$. We have&lt;/p&gt;
&lt;p&gt;$$P(x_1 \vee x_2) = \frac{315,182,658}{3,814,660,340,689,757} \approx 8.262\times 10^{-8}. $$&lt;/p&gt;
&lt;p&gt;If we are only interested in this outcome, we can treat our outcome as a Bernoulli variable with $p=P(x_1 \vee x_2)$. Then the expected number of games we need to play to win a million dollars or more is distributed like a geometric with $E[G] = 1/p$. For our specific case:&lt;/p&gt;
&lt;p&gt;$$ E[G] = \frac 1 p = \frac{3,814,660,340,689,757}{315,182,658} \approx 12,103,014.$$&lt;/p&gt;
&lt;p&gt;Recall that two games are played per week. Converting this expected number of games to years, it would take approximately $115,977$ years for us to win. Even if one drawing were held each day, we would expect to take more than $33,000$ years to win.&lt;/p&gt;
&lt;p&gt;Since the CDF of the geometric distribution is well defined, we can use it to estimate the number of games required for a certain likelihood of having a win of at least a million dollars. To have roughly 50% odds of winning, we need to play about $8,400,000$ games of Mega Millions. Note that in this case you would still likely be in the hole since the $1,000,000$ USD jackpot is nearly 24 times more likely than the main jackpot and each game costs 2 USD to play.&lt;/p&gt;
&lt;h3 id=&#34;simulating-a-lifetime-of-playing&#34;&gt;Simulating a Lifetime of Playing&lt;/h3&gt;
&lt;p&gt;At this point you might agree that the lottery is not a good get-rich-quick scheme. That alone doesn&amp;rsquo;t mean that you are all but guaranteed to loose money over a lifetime of playing. So let&amp;rsquo;s run some simulations and see what the distribution of our net worth is after taking everything into account. To make things as fair as possible, we will assume a constant jackpot of 750 million USD.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s say you spend 50 years playing the Mega Millions at 2 USD for one ticket at each of the two weekly drawings. That comes out to just about $2,609$ weeks or $5,218$ games for a total price of $10,436$ USD. I simulated $50,000$ individuals each playing $5,218$ games for a constant jackpot of $750,000,000$ USD - much higher than the 
&lt;a href=&#34;https://www.megamillions.com/jackpot-history&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;typical jackpot&lt;/a&gt; and advantageous to the players. This will cost them each $10,436$ USD in ticket costs over the 50 years they play. Yet, despite the simulated lottery being rigged in the players&#39; favor, 99% of my players win less than 600 USD total over this 50 year time period.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Statistic&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;Value ($)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Mean&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;-9,169.43&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;SD&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;20,985.05&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Min&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;-9,974.00&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;25%&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;-9,912.00&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;50%&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;-9,898.00&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;75%&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;-9,890.00&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;99%&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;-9,884.00&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Max&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;1,990,204.00&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;From these results it is clear that for all but the luckiest few, even just saving the money under a mattress outperforms playing the lottery. You can explore a distribution plot of my simulation with Plotly 
&lt;a href=&#34;results.html&#34;&gt;here&lt;/a&gt;. Note that this page may take a moment to load due to the many data points. You will need to zoom in on the left-hand side to be able really make anything out.&lt;/p&gt;
&lt;h4 id=&#34;implementation-note&#34;&gt;Implementation Note&lt;/h4&gt;
&lt;p&gt;The number of simulations grows quickly given the $5,218$ games we are using. Doing $50,000$ simulations of that many games requires over 260 million random draws. Prototyping in Python often makes sense because of the many features available for analysis and plotting, but this seems like an example where a compiled language might outperform by a considerable amount. I decided to 
&lt;a href=&#34;https://github.com/dmsenter89/lottery-sims&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;try this out (GitHub)&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;All of the programs were written with an emphasis on simplicity over performance so as to avoid biasing the results. Since the different individuals play their games independently, I wrote both a single-threaded C++ version as well as one utilizing OpenMP&amp;rsquo;s parallel for loop. As alternative compiled languages I added implementations in Go and Rust.&lt;/p&gt;
&lt;p&gt;For scripting languages I included Python and Julia. In Julia the main loop can trivially be set to run concurrently by prepending &lt;code&gt;Threads.@threads&lt;/code&gt; to the for loop, so inlcuded that as an option as well. This instructs the Julia interpreter to run this loop with the available threads. By default this is one, but can be set higher using an environment variable or by starting Julia with the &lt;code&gt;-t&lt;/code&gt; flag and specifying the desired number of threads.&lt;/p&gt;
&lt;p&gt;I used 
&lt;a href=&#34;https://github.com/sharkdp/hyperfine&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;hyperfine (GitHub)&lt;/a&gt; to benchmark the performance of my programs in WSL; see output below for details.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Command&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;Mean [s]&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;Min [s]&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;Max [s]&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;Relative&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;C++ (Single Thread)&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;4.602 ± 0.087&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;4.514&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;4.828&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;1.88 ± 0.06&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;C++ (OpenMP)&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;2.653 ± 0.170&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;2.506&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;3.092&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;1.08 ± 0.07&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Go&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;9.362 ± 0.058&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;9.258&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;9.417&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;3.83 ± 0.10&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Julia&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;28.606 ± 0.372&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;28.198&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;29.520&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;11.69 ± 0.33&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Julia (4 Threads)&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;19.016 ± 0.274&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;18.673&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;19.511&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;7.77 ± 0.23&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Python&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;57.727 ± 0.530&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;59.783 ± 3.811&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;57.833&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;70.242&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Rust&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;2.447 ± 0.062&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;2.391&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;2.579&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;1.00&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;I was surprised by Rust&amp;rsquo;s performance. I only looked up enough Rust to be able to implement this simple example, so I find it surprising that it can keep up with a multi-threaded C++ implementation.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Updates: This blogpost has been updated with new benchmark values. The original post did not include results in Rust.&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Life Expectancy Data</title>
      <link>https://dmsenter89.github.io/post/22-09-life-expectancy/</link>
      <pubDate>Fri, 02 Sep 2022 13:11:30 +0000</pubDate>
      <guid>https://dmsenter89.github.io/post/22-09-life-expectancy/</guid>
      <description>&lt;p&gt;Most people can guess the current life expectancy for Americans at birth as being in the high 70s or around 80. In fact, given the 
&lt;a href=&#34;https://www.ssa.gov/oact/STATS/table4c6.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;current mortality table&lt;/a&gt; published by the Social Security Administration (SSA), males have a life expectancy of about 76 compared to a female life expectancy of about 81. Of course that is only an expected value. Guessing the &lt;em&gt;distribution&lt;/em&gt; of a person&amp;rsquo;s life expectancy is somewhat more difficult. In this post, we&amp;rsquo;ll take a look at some simulated lives to get a feel for the distribution of life expectancy and its implications for retirement planning.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s begin by looking at our mortality table. The rows indicate an individual&amp;rsquo;s current age. For both a male and a female, three values are then given: the probability of death in a given year, the &amp;ldquo;Number of Lives&amp;rdquo;, and the life expectancy for this individual. The probability of death in a given year is somewhat self-explanatory. The &amp;ldquo;Number of Lives&amp;rdquo; variable starts with 100,000 individuals and gives the number of survivors at a given age. So for example, of the 100,000 males &amp;ldquo;born&amp;rdquo; at age 0, we expect 99,392 to be alive at age 1. The life expectancy is the expected number of years of life remaining for an individual. We can start by plotting this to get a feel for the data.&lt;/p&gt;





  
  











&lt;figure id=&#34;figure-survival-curve-for-100000-males-and-females-given-the-2019-ssa-mortality-tables-the-dashed-line-indicates-the-typical-retirement-age-of-67&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://dmsenter89.github.io/post/22-09-life-expectancy/survivalPlot_hu8976ee6293875d841810953bda6bf5f5_123683_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;Survival curve for 100,000 males and females given the 2019 SSA mortality tables. The dashed line indicates the typical retirement age of 67.&#34;&gt;


  &lt;img data-src=&#34;https://dmsenter89.github.io/post/22-09-life-expectancy/survivalPlot_hu8976ee6293875d841810953bda6bf5f5_123683_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;2606&#34; height=&#34;1684&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Survival curve for 100,000 males and females given the 2019 SSA mortality tables. The dashed line indicates the typical retirement age of 67.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;To get a feeling for the distribution of age at death, I ran 10,000 simulations each for males and females starting at ages 0, 25, 40, 60, and 80. These ages were chosen to represent the full range of possibilities at birth, followed by early, mid- and late career individuals. Age 80 was included for comparison as an older retiree value. Since the probability of death by age 50 is so low, we expect very little difference for the first three ages, with differences becoming more pronounced as age progresses, but it is still useful to visualize.&lt;/p&gt;





  
  











&lt;figure id=&#34;figure-overview-of-the-distribution-of-age-at-death-by-sex-for-different-ages-at-the-beginning-of-the-simulation-outliers-are-are-not-represented-note-how-the-results-for-ages-0-to-40-are-nearly-indistinguishable&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://dmsenter89.github.io/post/22-09-life-expectancy/Sample_Overview_hub6662c611b080d5ff9aca3d611ac8c57_52510_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;Overview of the distribution of age at death by sex for different ages at the beginning of the simulation. Outliers are are not represented. Note how the results for ages 0 to 40 are nearly indistinguishable.&#34;&gt;


  &lt;img data-src=&#34;https://dmsenter89.github.io/post/22-09-life-expectancy/Sample_Overview_hub6662c611b080d5ff9aca3d611ac8c57_52510_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;2606&#34; height=&#34;1684&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Overview of the distribution of age at death by sex for different ages at the beginning of the simulation. Outliers are are not represented. Note how the results for ages 0 to 40 are nearly indistinguishable.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;As expected, we see relatively little variation between birth and age 40, with some recognizable changes beginning at age 60. Given that, I will visualize the distribution for an individual starting at age 40. A 40 year old is about 25-30 years away from retirement and has probably at least started thinking about saving and how much they&amp;rsquo;ll need to put away to last through retirement.&lt;/p&gt;





  
  











&lt;figure id=&#34;figure-distribution-of-age-at-death-for-males-and-females-given-a-starting-age-of-40-half-of-the-starting-population-is-expected-to-make-it-to-at-least-8185-malefemale-and-a-quarter-will-make-it-at-least-to-8891&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://dmsenter89.github.io/post/22-09-life-expectancy/distributionPlot_hue89b8b06e05cd8b82745d76fbdceaf60_146013_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;Distribution of age at death for males and females given a starting age of 40. Half of the starting population is expected to make it to at least 81/85 (Male/Female), and a quarter will make it at least to 88/91.&#34;&gt;


  &lt;img data-src=&#34;https://dmsenter89.github.io/post/22-09-life-expectancy/distributionPlot_hue89b8b06e05cd8b82745d76fbdceaf60_146013_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;2606&#34; height=&#34;1684&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Distribution of age at death for males and females given a starting age of 40. Half of the starting population is expected to make it to at least 81/85 (Male/Female), and a quarter will make it at least to 88/91.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;So now that have seen the distribution, let&amp;rsquo;s consider how long we&amp;rsquo;ll live past the typical retirement age of 67. The table below lists the ages by sex for the top percentiles given a starting age of 40.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Top Percentiles - Age at Death&lt;/th&gt;
&lt;th&gt;Males&lt;/th&gt;
&lt;th&gt;Females&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;5%&lt;/td&gt;
&lt;td&gt;95&lt;/td&gt;
&lt;td&gt;98&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;10%&lt;/td&gt;
&lt;td&gt;93&lt;/td&gt;
&lt;td&gt;95&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;20%&lt;/td&gt;
&lt;td&gt;89&lt;/td&gt;
&lt;td&gt;92&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;30%&lt;/td&gt;
&lt;td&gt;86&lt;/td&gt;
&lt;td&gt;90&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;40%&lt;/td&gt;
&lt;td&gt;84&lt;/td&gt;
&lt;td&gt;87&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;50%&lt;/td&gt;
&lt;td&gt;81&lt;/td&gt;
&lt;td&gt;85&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;We see that 40% of females and 30% of males are expected to live at least 20 years past retirement age. A little more than 5% of females will make it thirty years past retirement, but only 2.5% of males will. While only a small minority of retirees will need to fund their retirement for thirty or more years, it is not unreasonable to target retirement funds to last until we reach age 90.&lt;/p&gt;
&lt;p&gt;Unfortunately, a large share of Americans have insufficient 401k balances to cover their expected longevity (see 
&lt;a href=&#34;https://www.forbes.com/advisor/retirement/average-401k-balance-by-age/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;, 
&lt;a href=&#34;https://www.investopedia.com/articles/personal-finance/010616/whats-average-401k-balance-age.asp&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;, and 
&lt;a href=&#34;https://mint.intuit.com/blog/retirement/average-401k-balance-by-age/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt; for some estimates of savings by age group). Many are likely relying on social security benefits to cover some of the difference. This system may not last that long, or at least not with current benefit levels. Social Security outlays have exceeded allocated revenues since 2010 and are currently expected to continue to do so well into the 2090s (see 
&lt;a href=&#34;https://www.cbo.gov/publication/57342&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Table A-1&lt;/a&gt;). Social security trust fund balances for old-age and survivor benefits are rapidly declining. Between 2020 and 2030, the CBO expects a drop of 80% in this fund. Curiously, over the same time period the trust fund for military personnel is expected to grow by more than 70%, while the fund for civilian government employees is expected to grow by more than 20% (see 
&lt;a href=&#34;https://www.cbo.gov/publication/56541&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CBO report&lt;/a&gt;). As such, younger Americans not working for the government will need to consider how to fund a multi-decade retirement in the face of potentially large reductions in social security benefits.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
