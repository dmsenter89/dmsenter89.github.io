<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>missing-data | Michael&#39;s Site</title>
    <link>https://dmsenter89.github.io/tag/missing-data/</link>
      <atom:link href="https://dmsenter89.github.io/tag/missing-data/index.xml" rel="self" type="application/rss+xml" />
    <description>missing-data</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Tue, 18 Feb 2025 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://dmsenter89.github.io/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png</url>
      <title>missing-data</title>
      <link>https://dmsenter89.github.io/tag/missing-data/</link>
    </image>
    
    <item>
      <title>New MI Post at SAS</title>
      <link>https://dmsenter89.github.io/post/25/02-new-mi-post-at-sas/</link>
      <pubDate>Tue, 18 Feb 2025 00:00:00 +0000</pubDate>
      <guid>https://dmsenter89.github.io/post/25/02-new-mi-post-at-sas/</guid>
      <description>&lt;p&gt;I wrote a blog post for 
&lt;a href=&#34;https://blogs.sas.com/content/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;blogs.sas.com&lt;/a&gt; that went
live yesterday. This post walks you through how to run a Bayesian regression model
with a multiply imputed data set such as those produced by PROC MI. What I like about
this process is that you can get started working with a Bayesian model that includes
missing data even if you&amp;rsquo;re not familiar with joint modeling techniques. It&amp;rsquo;s pretty neat
and allows for knowledge transfer between your frequentist and Bayesian methods.&lt;/p&gt;
&lt;p&gt;Go over to SAS to read my article entitled &amp;ldquo;
&lt;a href=&#34;https://blogs.sas.com/content/subconsciousmusings/2025/02/17/getting-started-performing-a-bayesian-analysis-with-missing-data-in-sas/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Getting started performing a Bayesian analysis with missing data in SAS
&lt;/a&gt;.&amp;rdquo;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Univariate Missing Data with PROC MI</title>
      <link>https://dmsenter89.github.io/post/23-08-univariate-mi/</link>
      <pubDate>Sun, 13 Aug 2023 00:00:00 +0000</pubDate>
      <guid>https://dmsenter89.github.io/post/23-08-univariate-mi/</guid>
      <description>&lt;p&gt;In Chapter 3 of van Buuren&amp;rsquo;s &lt;em&gt;Flexible Imputation of Missing Data&lt;/em&gt; a variety of methods for imputing univariate missing data are presented. This post will summarize these techniques and show how to implement them in SAS.&lt;/p&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#preliminaries&#34;&gt;Preliminaries&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#imputing-under-a-normal-linear-model&#34;&gt;Imputing under a Normal Linear Model&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#regression-imputation&#34;&gt;Regression Imputation&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#stochastic-regression-imputation&#34;&gt;Stochastic Regression Imputation&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#bayesianbootstrap-multiple-imputation&#34;&gt;Bayesian/Bootstrap Multiple Imputation&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#what-if-my-data-are-non-normal&#34;&gt;What if my data are non-normal?&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#predictive-mean-matching&#34;&gt;Predictive Mean Matching&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#classification-and-regression-trees&#34;&gt;Classification and Regression Trees&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#the-propensity-score-method&#34;&gt;The Propensity Score Method&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#categorical-and-count-data&#34;&gt;Categorical and Count Data&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#the-logistic-and-logit-models&#34;&gt;The Logistic and Logit Models&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#the-discriminant-function-method&#34;&gt;The Discriminant Function Method&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#references&#34;&gt;References&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;

&lt;h2 id=&#34;preliminaries&#34;&gt;Preliminaries&lt;/h2&gt;
&lt;p&gt;Van Buuren demonstrates various techniques using data set 88 from Hand et al (1994). This data set is availabe from R&amp;rsquo;s MASS library as &lt;code&gt;data(&amp;quot;whiteside&amp;quot;)&lt;/code&gt;. The original data set can be downloaded from the 
&lt;a href=&#34;https://www.routledge.com/A-Handbook-of-Small-Data-Sets/Hand-Daly-McConway-Lunn-Ostrowski/p/book/9780367449667&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;publisher&amp;rsquo;s website&lt;/a&gt;. The name of the relevant data file is INSULATE.DAT. If you want to follow along using SAS, you can use 
&lt;a href=&#34;./code/whiteside.sas&#34;&gt;this data step&lt;/a&gt;. It matches the way the data appears in R except that I have added a variable &lt;code&gt;R&lt;/code&gt; indicating the observation that van Buuren deletes for demonstration purposes.&lt;/p&gt;
&lt;p&gt;For purposes of this post, we assume one or more predictors $x$ are completely observed, while some variable of interest $y$ is only partially observed. Methods for dealing with this type of problem are available using the 
&lt;a href=&#34;http://documentation.sas.com/doc/en/statug/15.2/statug_mi_syntax09.htm&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;monotone&lt;/a&gt; keyword in PROC MI. A data set has a monotone missing pattern if it consists of variables $Y_1$, $Y_2$, $\ldots$, $Y_p$ such that if $Y_j$ is missing for one individual, all subsequent variables $Y_k$ for $j &amp;lt; k \leq p$ are also missing. Schematically, the data set will look like this:&lt;/p&gt;
&lt;p&gt;$$R = \begin{bmatrix} 1 &amp;amp; 1 &amp;amp; 1 \\ 1 &amp;amp; 1 &amp;amp; 0 \\ 1 &amp;amp; 0 &amp;amp; 0 \end{bmatrix}$$&lt;/p&gt;
&lt;p&gt;where 1 indicates an observed value and 0 a missing value. The monotone statement in SAS can impute missing values by completing the columns in turn using univariate methods. See the 
&lt;a href=&#34;http://documentation.sas.com/doc/en/statug/15.2/statug_mi_details06.htm&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SAS documentation&lt;/a&gt; for specifics.&lt;/p&gt;
&lt;h2 id=&#34;imputing-under-a-normal-linear-model&#34;&gt;Imputing under a Normal Linear Model&lt;/h2&gt;
&lt;p&gt;For completion, I will mention all of the main linear model methods van Buuren mentions in his text, even though the first two are not implemented in PROC MI.&lt;/p&gt;
&lt;h3 id=&#34;regression-imputation&#34;&gt;Regression Imputation&lt;/h3&gt;
&lt;p&gt;Van Buuren also refers to this as the &amp;ldquo;prediction&amp;rdquo; method. In essence, the complete cases are used to create a linear model. This linear model is then used to fill in the missing values:&lt;/p&gt;
&lt;p&gt;$$ \dot{y} = \hat\beta_0 + X_\text{mis}\,\hat\beta_1$$&lt;/p&gt;
&lt;p&gt;where $\hat\beta_i$ are least squares estimates.&lt;/p&gt;
&lt;p&gt;This method has a variety of drawbacks. For one, it artificially strengthens the relationships between variables as they appear in the linear model by increasing correlations. Variability in the data is reduced. See section 
&lt;a href=&#34;https://stefvanbuuren.name/fimd/sec-simplesolutions.html#sec:regimp&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;1.3.4&lt;/a&gt; in van Buuren for details.&lt;/p&gt;
&lt;p&gt;The mice package implements this method as &lt;code&gt;norm.predict&lt;/code&gt;. PROC MI does not implement this method; to use this technique in SAS, you could use the regression PROCs or IML.&lt;/p&gt;
&lt;h3 id=&#34;stochastic-regression-imputation&#34;&gt;Stochastic Regression Imputation&lt;/h3&gt;
&lt;p&gt;This method proceeds as above, except that Gaussian noise is added to the imputed value:
$$ \dot{y} = \hat\beta_0 + X_\text{mis}\,\hat\beta_1 + \dot\epsilon$$
where $\dot\epsilon \sim N(0, \hat\sigma^2)$. An advantage of this method over plain regression is that it can preserve correlation between variables.&lt;/p&gt;
&lt;p&gt;The mice package implements this method as &lt;code&gt;norm.nob&lt;/code&gt;. It is not available in PROC MI but can be implemented with IML.&lt;/p&gt;
&lt;h3 id=&#34;bayesianbootstrap-multiple-imputation&#34;&gt;Bayesian/Bootstrap Multiple Imputation&lt;/h3&gt;
&lt;p&gt;Van Buuren also refrers to this as &amp;ldquo;predict + noise + parameters uncertainty.&amp;rdquo; This technique is based on a Bayesian linear regression using draws from the posterior as parameters:
$$\dot y = \dot\beta_0 + X_\text{mis}\, \dot\beta_1 + \dot\epsilon$$
where $\dot\epsilon\sim N(0,\dot\sigma^2)$ and $\dot\beta_i$, $\dot\sigma$ are random draws from the posterior distribution.&lt;/p&gt;
&lt;p&gt;This the default method in PROC MI for continuous data. Both SAS and mice use an algorithm based on Rubin (1987, pp. 166-167). See the 
&lt;a href=&#34;http://documentation.sas.com/doc/en/statug/15.2/statug_mi_details07.htm&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SAS documentation&lt;/a&gt; and 
&lt;a href=&#34;https://stefvanbuuren.name/fimd/sec-linearnormal.html#def:norm&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Algorithm 3.1&lt;/a&gt; in van Buuren for details. The mice package implements this method as &lt;code&gt;norm&lt;/code&gt;. Here is an example of how the Bayesian regression can be used in PROC MI:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sas&#34;&gt;proc mi data=whiteside_miss out=regimp nimpute=5;
	var temp gas;
	monotone regression(gas);
run;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The regression keyword may be abbreviated as &lt;code&gt;reg&lt;/code&gt;. A fully worked example is available in the 
&lt;a href=&#34;https://documentation.sas.com/doc/en/statug/15.2/statug_mi_examples03.htm&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SAS documentation&lt;/a&gt;, with the associated code available on 
&lt;a href=&#34;https://github.com/sassoftware/doc-supplement-statug/blob/main/Examples/m-n/miex3.sas&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The mice package also implements a variant of this method using bootstrapping instead of a Bayesian model. This method is available as &lt;code&gt;norm.boot&lt;/code&gt;.&lt;/p&gt;
&lt;h3 id=&#34;what-if-my-data-are-non-normal&#34;&gt;What if my data are non-normal?&lt;/h3&gt;
&lt;p&gt;In case the data are non-normal, one could proceed to a non-regression technique like 
&lt;a href=&#34;#predictive-mean-matching&#34;&gt;predictive mean matching&lt;/a&gt;. Alternatively, one could adjust the regression methods to utizilise a generalized linear model instead. That technique is implemented in the 
&lt;a href=&#34;https://github.com/dsalfran/ImputeRobust&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ImputeRobust&lt;/a&gt; package for R. See section 
&lt;a href=&#34;https://stefvanbuuren.name/fimd/sec-nonnormal.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;3.3&lt;/a&gt; in van Buuren for details.&lt;/p&gt;
&lt;h2 id=&#34;predictive-mean-matching&#34;&gt;Predictive Mean Matching&lt;/h2&gt;
&lt;p&gt;Similar to 
&lt;a href=&#34;#bayesianbootstrap-multiple-imputation&#34;&gt;Bayesian regression&lt;/a&gt; above, a predicted value is calculated for each missing observation. Instead of adding noise to this prediction, however, a set of $k$ observations whose predicted values are close to the predicted missing value are sought. The missing value is then replaced by a random draw from this set of candidate donors. In mice, this method is available as &lt;code&gt;pmm&lt;/code&gt;. In PROC MI, you can use the &lt;code&gt;regpredmeanmatch&lt;/code&gt; keyword:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sas&#34;&gt;proc mi data=whiteside_miss out=regimp nimpute=5;
	var temp gas;
	monotone regpredmeanmatch(gas);
run;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The keyword &lt;code&gt;regpredmeanmatch&lt;/code&gt; may be abbreviated as &lt;code&gt;regpmm&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The predictive mean matching method is robust to transformations of the target variable. It may be used with both continuous and discrete data and will always generate realistic data in the sense that all generated data has been observed. Since this does not require an explicit model to describe the distribution of missing values, it is more resilient to model misspecification.&lt;/p&gt;
&lt;p&gt;See the 
&lt;a href=&#34;https://documentation.sas.com/doc/en/statug/15.2/statug_mi_details08.htm&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SAS documentation&lt;/a&gt; and 
&lt;a href=&#34;https://stefvanbuuren.name/fimd/sec-pmm.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;section 3.4&lt;/a&gt; in van Buuren for details.&lt;/p&gt;
&lt;h2 id=&#34;classification-and-regression-trees&#34;&gt;Classification and Regression Trees&lt;/h2&gt;
&lt;p&gt;An idea borrowed from the machine learning community and implemented in some R packages. In essence, the idea is similar to utiziling linear regression models except that a regression tree is utilized instead. See 
&lt;a href=&#34;https://stefvanbuuren.name/fimd/sec-cart.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;section 3.5&lt;/a&gt; in van Buuren.&lt;/p&gt;
&lt;h2 id=&#34;the-propensity-score-method&#34;&gt;The Propensity Score Method&lt;/h2&gt;
&lt;p&gt;With this method, propensity scores are generated for each observation estimating the probability of it being missing. The observations are then grouped by their propensity scores and an approximate Bayesian bootstrap imputation is carried out for each group. See 
&lt;a href=&#34;https://documentation.sas.com/doc/en/statug/15.2/statug_mi_details18.htm&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SAS documentation&lt;/a&gt; for details.&lt;/p&gt;
&lt;p&gt;A fully worked example is available in the 
&lt;a href=&#34;https://documentation.sas.com/doc/en/statug/15.2/statug_mi_examples02.htm&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SAS documentation&lt;/a&gt;, with the associated code available on 
&lt;a href=&#34;https://github.com/sassoftware/doc-supplement-statug/blob/main/Examples/m-n/miex2.sas&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GitHub&lt;/a&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sas&#34;&gt;proc mi data=Fish1 out=outex2;
   monotone propensity;
   var Length1 Length2 Length3;
run;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This method is not implemented in the mice package.&lt;/p&gt;
&lt;h2 id=&#34;categorical-and-count-data&#34;&gt;Categorical and Count Data&lt;/h2&gt;
&lt;h3 id=&#34;the-logistic-and-logit-models&#34;&gt;The Logistic and Logit Models&lt;/h3&gt;
&lt;p&gt;Logit based regression models can be used both for nominal and ordinal data. The imputed value is generated from a Bayesian logistic regression model. The mice package implements this method as &lt;code&gt;logreg&lt;/code&gt;. PROC MI uses the &lt;code&gt;logistic&lt;/code&gt; keyword. An example of its usage is given in the 
&lt;a href=&#34;https://documentation.sas.com/doc/en/statug/15.2/statug_mi_examples04.htm&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SAS documentation&lt;/a&gt;, with the associated code available on 
&lt;a href=&#34;https://github.com/sassoftware/doc-supplement-statug/blob/main/Examples/m-n/miex4.sas&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GitHub&lt;/a&gt;. Here&amp;rsquo;s the example code:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sas&#34;&gt;proc mi data=Fish2 out=outex4;
   class Species;
   monotone reg(Width/ details)
            logistic(Species = Length Width Length*Width/ details);
   var Length Width Species;
run;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This imputes the width variable using the 
&lt;a href=&#34;#bayesianbootstrap-multiple-imputation&#34;&gt;Bayesian linear regression&lt;/a&gt; while imputing the categorical species variable using the logistig regression method.&lt;/p&gt;
&lt;p&gt;See the 
&lt;a href=&#34;https://documentation.sas.com/doc/en/statug/15.2/statug_mi_details13.htm&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SAS documentation&lt;/a&gt; for details.&lt;/p&gt;
&lt;h3 id=&#34;the-discriminant-function-method&#34;&gt;The Discriminant Function Method&lt;/h3&gt;
&lt;p&gt;This method is the default for categorical data in PROC MI. See the 
&lt;a href=&#34;https://documentation.sas.com/doc/en/statug/15.2/statug_mi_details09.htm&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SAS documentation&lt;/a&gt; for details.&lt;/p&gt;
&lt;p&gt;A fully worked example is available in the 
&lt;a href=&#34;https://documentation.sas.com/doc/en/statug/15.2/statug_mi_examples05.htm&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SAS documentation&lt;/a&gt;, with the associated code available on 
&lt;a href=&#34;https://github.com/sassoftware/doc-supplement-statug/blob/main/Examples/m-n/miex5.sas&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GitHub&lt;/a&gt;. Here is the MI call:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sas&#34;&gt;proc mi data=Fish2 out=outex5;
   class Species;
   monotone discrim(Species = Length Width/ details);
   var Length Width Species;
run;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The mice package does not implement this method.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;p&gt;Hand, D. J., F. Daly, A. D. Lunn, K. J. McConway, and Ostrowski,  E. (1994), &lt;em&gt;A Handbook of Small Data Sets&lt;/em&gt;, London: Chapman &amp;amp; Hall.&lt;/p&gt;
&lt;p&gt;Rubin, D. B. (1987), &lt;em&gt;Multiple Imputation for Nonresponse in Surveys&lt;/em&gt;, New York: John Wiley &amp;amp; Sons.&lt;/p&gt;
&lt;p&gt;van Buuren, S. (2018), &lt;em&gt;Flexible Imputation of Missing Data&lt;/em&gt;, Chapman and Hall/CRC interdisciplinary statistics series, Boca Raton: CRC Press, Taylor and Francis Group. Available at &lt;a href=&#34;https://stefvanbuuren.name/fimd/&#34;&gt;https://stefvanbuuren.name/fimd/&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>PROC MI Added to SASPy</title>
      <link>https://dmsenter89.github.io/post/23-02-proc-mi-added-to-saspy/</link>
      <pubDate>Mon, 06 Feb 2023 14:45:00 -0500</pubDate>
      <guid>https://dmsenter89.github.io/post/23-02-proc-mi-added-to-saspy/</guid>
      <description>&lt;p&gt;I&amp;rsquo;m excited to announce that the new 
&lt;a href=&#34;https://github.com/sassoftware/saspy/releases/tag/v4.6.0&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SAPy v4.6.0&lt;/a&gt; release includes a pull request of mine that adds 
&lt;a href=&#34;https://go.documentation.sas.com/doc/en/statug/15.2/statug_mi_toc.htm&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PROC MI&lt;/a&gt; to the SAS/STAT procedures directly exposed in SASPy. This procedure allows you to analyze missing data patterns and create imputations for missing data.&lt;/p&gt;
&lt;h2 id=&#34;syntax&#34;&gt;Syntax&lt;/h2&gt;
&lt;p&gt;PROC MI is accessed via the &lt;code&gt;mi&lt;/code&gt; function that has been added to the &lt;code&gt;SASstat&lt;/code&gt; class. Like other procedures, the SAS statements in MI are called as keyword arguments to the function whose name matches the SAS 
&lt;a href=&#34;https://go.documentation.sas.com/doc/en/statug/15.2/statug_mi_syntax.htm&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;syntax&lt;/a&gt;:&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sas&#34;&gt;PROC MI options;
  BY variables;
  CLASS variables;
  EM &amp;lt;options&amp;gt;;
  FCS &amp;lt;options&amp;gt;;
  FREQ variable;
  MCMC &amp;lt;options&amp;gt;;
  MNAR options;
  MONOTONE &amp;lt;options&amp;gt;;
  TRANSFORM transform (variables&amp;lt;/ options&amp;gt;) &amp;lt;â€¦transform (variables&amp;lt;/ options&amp;gt;)&amp;gt;;
  VAR variables;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here is the corresponding function signature in Python:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def mi(self, data: (&#39;SASdata&#39;, str) = None,
        by: (str, list) = None,
        cls: (str, list) = None,
        em: str = None,
        fcs: str = None,
        freq: str = None,
        mcmc: str = None,
        mnar: str = None,
        monotone: str = None,
        transform: str = None,
        var: str = None,
        procopts: str = None,
        stmtpassthrough: str = None,
        **kwargs: dict) -&amp;gt; &#39;SASresults&#39;:
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Statements  like &lt;code&gt;EM&lt;/code&gt; or &lt;code&gt;MCMC&lt;/code&gt;, which can stand alone in SAS, are called with an empty string argument in Python.&lt;/p&gt;
&lt;h2 id=&#34;basic-example&#34;&gt;Basic Example&lt;/h2&gt;
&lt;!-- 
```python saspy_mi.py
#!/usr/bin/env python3
#
# Example: how to access PROC MI with SASPy. To accompany
#   dmsenter89.github.io/post/23-02-proc-mi-added-to-saspy
# 
# Author: Michael Senter, PhD

import saspy


# starting the SAS Session
&lt;&lt;&lt;session&gt;&gt;&gt;

&lt;&lt;&lt;procmi&gt;&gt;&gt;

&lt;&lt;&lt;sasdata&gt;&gt;&gt;


# ending the SAS session 
sas.endsas()
```
--&gt;
&lt;p&gt;To use the new MI functionality, make sure you have updated to the newest SASPy release. In addition to starting  a SAS Session as per usual, you will also want to enable access to the SAS/STAT procedures:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;sas = saspy.SASsession()  # loads a session using your default profile
stat = sas.sasstat()      # gives access to SAS/STAT procedures 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once these session objects are loaded, you can start using the mi function with &lt;code&gt;stat.mi&lt;/code&gt;. The simplest possible call is to invoke MI with a built-in data set and all defaults as &lt;code&gt;stat.mi(data=&#39;sashelp.heart&#39;)&lt;/code&gt;. For best results, store the output in a SASResults object. From there you can access the SAS log associated with the function call (&lt;code&gt;LOG&lt;/code&gt;) as well as all ODS Output using the ODS 
&lt;a href=&#34;https://go.documentation.sas.com/doc/en/statug/15.2/statug_mi_details82.htm&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;table names&lt;/a&gt; in all caps. The default uses the EM method with 25 imputations.&lt;/p&gt;
&lt;p&gt;A more realistic use might look something like this:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;ods = stat.mi(data=&#39;sashelp.heart&#39;, em=&amp;quot;outem=outem&amp;quot;,
              var=&amp;quot;Cholesterol Height Smoking Weight&amp;quot;,
              procopts=&amp;quot;simple nimpute=20 out=imp&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is equivalent to running&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sas&#34;&gt;proc mi data=sashelp.heart simple nimpute=20 out=imp;
    em outem=outem;
    var Cholesterol Height Smoking Weight;
run;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;in SAS. This call uses the EM procedure to impute values for the cholesterol, height, smoking, and weight variables. The &lt;code&gt;simple&lt;/code&gt; option displays univariate statistics and correlations. The &lt;code&gt;outem&lt;/code&gt; option saves a data set containing the computed MLE to &lt;code&gt;work.outem&lt;/code&gt;. The imputed data sets are saved to &lt;code&gt;work.imp&lt;/code&gt;, which contains the additional variable &lt;code&gt;_IMPUTATION_&lt;/code&gt; with the imputation number. This can be used as a &lt;code&gt;by&lt;/code&gt; variable in other procedures, and the results can later be pooled using PROC MIANALYZE.&lt;/p&gt;
&lt;p&gt;The resulting &lt;code&gt;ods&lt;/code&gt; object for our example exposes the following ODS outputs to your Python instance, in addition to the log:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[&#39;CORR&#39;, &#39;EMESTIMATES&#39;, &#39;EMINITESTIMATES&#39;, &#39;EMPOSTESTIMATES&#39;, &#39;MISSPATTERN&#39;, &#39;MODELINFO&#39;, &#39;PARAMETERESTIMATES&#39;, &#39;UNIVARIATE&#39;, &#39;VARIANCEINFO&#39;]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;See the SAS documentation for details. To use the imputed data with Python tools, create a SAS data object. We&amp;rsquo;ll also print the first few entries so we can see what it looks like:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;imputed = sas.sasdata(table=&amp;quot;imp&amp;quot;, libref=&amp;quot;work&amp;quot;)
imputed.head()
&lt;/code&gt;&lt;/pre&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;One exception is the SAS &lt;code&gt;class&lt;/code&gt; statement, which is implemented as &lt;code&gt;cls&lt;/code&gt; due to &lt;code&gt;class&lt;/code&gt; being a reserved keyword in Python. &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
    <item>
      <title>Missing Data Mechanisms</title>
      <link>https://dmsenter89.github.io/post/23-01-missing-data-mechanisms/</link>
      <pubDate>Tue, 03 Jan 2023 10:00:00 -0500</pubDate>
      <guid>https://dmsenter89.github.io/post/23-01-missing-data-mechanisms/</guid>
      <description>&lt;p&gt;Understanding whether a variable&amp;rsquo;s missingness from a dataset is related to the underlying value of the data is a key concept in the field of missing data analysis. We distinguish three broad categories: missing completely at random (MCAR), missing at random (MAR), and missing not at random (MNAR). In his book &lt;em&gt;Statistical Rethinking&lt;/em&gt;, McElreath&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; gives an amusing example to illustrate this concept: he considers variants of a dog eating homework and how the dog chooses - if at all - to eat the homework. The examples he give show substantial shifts in observed values, which make for a good illustration of the types of problems you might encounter. A lecture corresponding to the  example from the book can be found on 
&lt;a href=&#34;https://www.youtube.com/watch?v=oMiSb8GKR0o&amp;amp;list=PLDcUM9US4XdMROZ57-OIRtIK0aOynbgZN&amp;amp;index=18&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;YouTube&lt;/a&gt;. In this post, I will first briefly review the different missing data mechanisms before implementing McElreath&amp;rsquo;s examples in SAS.&lt;/p&gt;
&lt;h3 id=&#34;overview-of-missing-data-mechanisms&#34;&gt;Overview of Missing Data Mechanisms&lt;/h3&gt;
&lt;p&gt;My presentation here follows van Buuren&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;. Let $Y$ be a $n \times p$ matrix representing a sample of $p$ variables for $n$ units of the sample and $R$ be a corresponding $n \times p$ indicator matrix, so that&lt;/p&gt;
&lt;p&gt;$$r_{i,j} = \begin{cases} 1 &amp;amp; y_{i,j} \text{ is observed} \\ 0 &amp;amp; y_{i,j} \text{ not observed.}\end{cases} $$&lt;/p&gt;
&lt;p&gt;We denote the observed data by $Y_\text{obs}$ and the missing data that $Y_\text{miss}$ so that $Y=(Y_\text{obs},Y_\text{miss})$.&lt;/p&gt;
&lt;p&gt;We distinguish three main categories for how the distribution of $R$ may depend on $Y$. This relationship is described as the &lt;em&gt;missing data model&lt;/em&gt;. Let $\psi$ contain the parameters of this model. The general expression of the missing data model is $\mathrm{Pr}(R|Y_\text{obs}, Y_\text{miss}, \psi)$, where $\psi$ consists of the parameters of the missing data model.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Missing Completely at Random (MCAR).&lt;/strong&gt; This implies that the cause of the missing data is unrelated to the data itself. In this case,&lt;/p&gt;
&lt;p&gt;$$ \mathrm{Pr}(R=0| Y_\text{obs}, Y_\text{miss}, \psi) = \mathrm{Pr}(R=0|\psi).$$&lt;/p&gt;
&lt;p&gt;This is the ideal case, but unfortunately rare in practice. Many researchers implicitly assume this when using methods such as list-wise deletion, otherwise known as complete case analysis, which can produce unbiased estimates of sample means if the data are MCAR, although the reported standard error will be too large.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Missing at Random (MAR).&lt;/strong&gt; Missingness is the same within groups defined by the observed data, so that&lt;/p&gt;
&lt;p&gt;$$ \mathrm{Pr}(R=0| Y_\text{obs}, Y_\text{miss}, \psi) = \mathrm{Pr}(R=0|Y_\text{obs},\psi).$$&lt;/p&gt;
&lt;p&gt;This is a often a more reasonable assumption in practice and the starting point for modern missing data methods.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Missing not at Random (MNAR).&lt;/strong&gt; If neither the MCAR or MAR assumptions hold, then we may find that missingness depends on the missing data itself, in which case there is no simplification and
$$ \mathrm{Pr}(R=0| Y_\text{obs}, Y_\text{miss}, \psi) = \mathrm{Pr}(R=0| Y_\text{obs}, Y_\text{miss}, \psi).$$&lt;/p&gt;
&lt;p&gt;As you can imagine, this is the most tricky case to deal with.&lt;/p&gt;
&lt;h3 id=&#34;dogs-eating-homework&#34;&gt;Dogs Eating Homework&lt;/h3&gt;
&lt;p&gt;Consider dogs (D) eating students&#39; homework. Each student&amp;rsquo;s homework score (H) is graded on a 10-point scale and each student&amp;rsquo;s score varies in proportion to how much they study (S). We assume the amount of time they study is normally distributed. A binomial is used to generate homework scores from the normed time spent studying. McElreath uses the following code to simulate the full data set:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-R&#34;&gt;N &amp;lt;- 100
S &amp;lt;- rnorm( N )
H &amp;lt;- rbinom( N, size=10, inv_logit(S) )
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;where &lt;code&gt;inv_logit(x) = exp(x)+(1+exp(x))&lt;/code&gt;, the definition used by the &lt;code&gt;LOGISTIC&lt;/code&gt; function in SAS. With a data step, this can be represented in SAS as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sas&#34;&gt;data full;
    DO i=1 to 100;
        S=RAND(&#39;NORM&#39;);
        H=RAND(&#39;BINO&#39;, LOGISTIC(S), 10);
        output;
    END;
    label S=&#39;Amount of Studying&#39; H=&#39;Homework Score&#39;;
    drop i;
run;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can get closer in form to the R code by using PROC IML, but that&amp;rsquo;s a story for a different post.&lt;/p&gt;
&lt;p&gt;Say we are interested in estimating the relationship between $S$ and $H$. In our example, we assume that $H$ is not directly observable. Instead, $H^*$ is observed - a subset of the full data set $H$ with some homework values missing. We can now look at &lt;em&gt;why&lt;/em&gt; some of those values are missing. Specifically, in McElreath&amp;rsquo;s example each student has a dog $D$ and sometimes the dog eats the homework. But here we can again ask, why is the dog eating the homework? McElreath uses  
&lt;a href=&#34;https://en.wikipedia.org/wiki/Directed_acyclic_graph&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;directed acyclic graphs&lt;/a&gt; (DAGs) to represent different missing data models, reproduced below. As we will see, these are some intuitive examples for our three missing data mechanism categories.&lt;/p&gt;





  
  











&lt;figure id=&#34;figure-the-directed-acyclic-graphs-corresponding-to-mcelreaths-examples-of-missing-data-models-s-represents-the-amount-of-time-spent-studying-which-in-turn-influences-the-homework-score-h-which-is-only-partially-observed-indicated-by-the-circle-alas-dogs-d-eat-some-of-the-homework-the-actually-observed-scores---those-not-eaten---are-indicated-by-h-adapted-from-figure-154-in-_statistical-rehinking_&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://dmsenter89.github.io/post/23-01-missing-data-mechanisms/dag_hu9d4aa2d4b53fa51c30ec3b81dc4e20f1_14343_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;The directed acyclic graphs corresponding to McElreath&amp;amp;rsquo;s examples of missing data models. $S$ represents the amount of time spent studying, which in turn influences the homework score $H$, which is only partially observed (indicated by the circle). Alas, dogs $D$ eat some of the homework. The actually observed scores - those not eaten - are indicated by $H^*$. Adapted from figure 15.4 in &amp;lt;em&amp;gt;Statistical Rehinking&amp;lt;/em&amp;gt;.&#34;&gt;


  &lt;img data-src=&#34;https://dmsenter89.github.io/post/23-01-missing-data-mechanisms/dag_hu9d4aa2d4b53fa51c30ec3b81dc4e20f1_14343_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;665&#34; height=&#34;179&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; class=&#34;numbered&#34;&gt;
    The directed acyclic graphs corresponding to McElreath&amp;rsquo;s examples of missing data models. $S$ represents the amount of time spent studying, which in turn influences the homework score $H$, which is only partially observed (indicated by the circle). Alas, dogs $D$ eat some of the homework. The actually observed scores - those not eaten - are indicated by $H^*$. Adapted from figure 15.4 in &lt;em&gt;Statistical Rehinking&lt;/em&gt;.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h4 id=&#34;missing-completely-at-random-mcar&#34;&gt;Missing Completely At Random (MCAR)&lt;/h4&gt;
&lt;p&gt;In the first example, the dogs eat homework completely at random. This is the most basic and benign case, and corresponds to DAG 1) in Figure 1. McElreath&amp;rsquo;s R code is given by&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-R&#34;&gt;D &amp;lt;- rbern( N ) 
Hm &amp;lt;- H  # H*, but * is not a valid char for varnames in R
Hm[D==1] &amp;lt;- NA
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can implement this in SAS by using the &lt;code&gt;RAND&lt;/code&gt; function with the Bernoulli argument in an if/else clause:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sas&#34;&gt;if RAND(&#39;BERN&#39;, 0.5) then Hm = .;
    else Hm = H;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This causes about half of our data to be hidden, but not in a biased way.&lt;/p&gt;
&lt;h4 id=&#34;missing-at-random-mar&#34;&gt;Missing at Random (MAR)&lt;/h4&gt;
&lt;p&gt;In the second example, we assume the amount of time a student spends studying decreases the amount of time they have to play with and exercise their dog. This, in turn, influences whether the homework gets eaten. Or, as McElreath puts it, the &amp;ldquo;dog eats conditional on the cause of homework.&amp;rdquo; In his particular example, the homework is eaten whenever a student spends more time studying than the average $S=0$. This corresponds to DAG 2) in Figure 1.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-R&#34;&gt;D &amp;lt;- ifelse( S&amp;gt;0 , 1 , 0 )
Hm &amp;lt;- H
Hm[D==1] &amp;lt;-NA
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In SAS:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sas&#34;&gt;if S&amp;gt;0 then Hm = .;
    else Hm = H;
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;missing-not-at-random-mnar&#34;&gt;Missing not at Random (MNAR)&lt;/h4&gt;
&lt;p&gt;In this case, we have some correspondence between the missing variable&amp;rsquo;s value and whether or not it is missing from the data set. Here, the &amp;ldquo;dog eats conditional on the homework itself.&amp;rdquo; Suppose that dogs prefer to eat bad homework. In such a case, the value of $H$ is directly related to whether or not $H$ is observed in the particular unit or not. His example R code is as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-R&#34;&gt;# dogs prefer bad homework
D &amp;lt;- ifelse( H&amp;lt;5 , 1 , 0 )
Hm &amp;lt;- H
Hm[D==1] &amp;lt;- NA
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And in SAS:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sas&#34;&gt;if H&amp;lt;5 then Hm = .;
    else Hm = H;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;the-full-sas-code&#34;&gt;The Full SAS Code&lt;/h3&gt;
&lt;p&gt;We can now build a SAS data set that contains a full copy of the original data set, together with our various examples of missing data mechanisms. I have added a seed to the data step for reproducibility.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sas&#34;&gt;data full;
    CALL streaminit( 451 ); 
    
    LABEL
        Type = &#39;Missing Data Mechanism&#39;
        S = &#39;Amount of Studying&#39;
        H = &#39;Homework Score&#39;
        Hm = &#39;Observed Homework Score&#39;
    ;

    DO i=1 to 100;
        TYPE = &#39;FULL&#39;;
        S = RAND(&#39;NORM&#39;);
        H = RAND(&#39;BINO&#39;, LOGISTIC(S), 10);
        Hm = H;
        output;
        
        /* Example 1) MCAR */
        TYPE = &#39;MCAR&#39;;
        if RAND(&#39;BERN&#39;, 0.5) then Hm = .;
            else Hm = H;
        output;
        
        /* Example 2) MAR */
        TYPE = &#39;MAR&#39;;
        if S&amp;gt;0 then Hm = .;
            else Hm = H;
        output;
        
        /* Example 3) MNAR */
        TYPE = &#39;MNAR&#39;;
        if H&amp;lt;5 then Hm = .;
            else Hm = H;
        output;
    
    END;
    
    drop i;
run;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You may want to run a &lt;code&gt;PROC SORT&lt;/code&gt; or &lt;code&gt;PROC SQL&lt;/code&gt; afterwards to group the different categories together, as they will be alternating in this data set.&lt;/p&gt;
&lt;h3 id=&#34;results&#34;&gt;Results&lt;/h3&gt;





  
  











&lt;figure id=&#34;figure-boxplot-of-our-example-data-note-that-the-mcar-data-looks-very-similar-to-the-original-data-set-unlike-the-mar-and-mnar-versions&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://dmsenter89.github.io/post/23-01-missing-data-mechanisms/mdm_boxplot_hu7d089ca360b9b11aaf1a482082b6d8dc_11177_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;Boxplot of our example data. Note that the MCAR data looks very similar to the original data set, unlike the MAR and MNAR versions.&#34;&gt;


  &lt;img data-src=&#34;https://dmsenter89.github.io/post/23-01-missing-data-mechanisms/mdm_boxplot_hu7d089ca360b9b11aaf1a482082b6d8dc_11177_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;640&#34; height=&#34;480&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; class=&#34;numbered&#34;&gt;
    Boxplot of our example data. Note that the MCAR data looks very similar to the original data set, unlike the MAR and MNAR versions.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;We can see that MCAR leads to minimal bias in our example data, while both the MAR and MNAR variations lead to substantial differences in observed vs actual homework scores for our synthetic population. For a more subtle example, see section 2.2.4 in van Buuren,&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt; available 
&lt;a href=&#34;https://stefvanbuuren.name/fimd/sec-idconcepts.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;online here&lt;/a&gt;.&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;R. McElreath, &lt;em&gt;Statistical Rethinking&lt;/em&gt;, 2nd ed, Chapman and Hall/CRC, Boca Raton, FL, 2020. &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;S. van Buuren, &lt;em&gt;Flexible Imputation of Missing Data&lt;/em&gt;, 2nd ed, Chapman and Hall/CRC, Boca Raton, FL, 2019. &lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
  </channel>
</rss>
