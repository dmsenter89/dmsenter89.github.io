<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>data-step | Michael&#39;s Site</title>
    <link>https://dmsenter89.github.io/tag/data-step/</link>
      <atom:link href="https://dmsenter89.github.io/tag/data-step/index.xml" rel="self" type="application/rss+xml" />
    <description>data-step</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Wed, 23 Nov 2022 16:43:28 +0000</lastBuildDate>
    <image>
      <url>https://dmsenter89.github.io/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png</url>
      <title>data-step</title>
      <link>https://dmsenter89.github.io/tag/data-step/</link>
    </image>
    
    <item>
      <title>CSV2DS</title>
      <link>https://dmsenter89.github.io/post/22-11-csv2ds/</link>
      <pubDate>Wed, 23 Nov 2022 16:43:28 +0000</pubDate>
      <guid>https://dmsenter89.github.io/post/22-11-csv2ds/</guid>
      <description>&lt;p&gt;Creating a minimum working example (MWE) is a relatively frequent task. It is no problem to share an MWE for a feature in SAS because a large number of example data sets are shipped and installed by default. But sometimes you need an MWE because you are having trouble accomplishing a particular task with particular input data. At that point, you will need to share the data or a subset thereof together with your code. In SAS Forums, the preferred way to do this is with a datastep using a datalines/cards statement. Writing these by hand can be tedious since the data source is not typically a datalines statement to begin with. I have previously seen a SAS macro that can be used to generate a datalines statement from a SAS data set, but can&amp;rsquo;t seem to locate it at the moment. The data source I personally encounter the most often in my work is either in CSV or Excel formats. Since the latter can easily be exported to CSV, I decided to write a program that generates a SAS data step given a CSV file.&lt;/p&gt;
&lt;p&gt;For the implementation language I chose to use 
&lt;a href=&#34;https://go.dev/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Go&lt;/a&gt;. I started learning about Go back in May when I implemented a 
&lt;a href=&#34;https://dmsenter89.github.io/post/22-05-go-wordle/&#34;&gt;simple CLI version of Wordle&lt;/a&gt;. Since then I have increasingly used Go to write various small tools at work. It has been a very enjoyable language to write in and distribution via GitHub is easy. If you have the Go toolchain installed, you can get the latest copy of csv2ds using&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;go install github.com/dmsenter89/csv2ds@latest
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The tool is very simple to use. Give it a CSV file or list of CSV files and it will generate a data step for each file using the CSV&amp;rsquo;s base name as the data set name. To ensure compatibility, variable names and the data set name are processed to be compatible with SAS&#39; naming scheme. The tool will attempt to guess if a particular column is numeric or not. If a column is determined to not be numeric, the longest cell will be used to set that variable&amp;rsquo;s length via a length statement to prevent truncation.&lt;/p&gt;
&lt;p&gt;I often work with the 
&lt;a href=&#34;https://csvkit.readthedocs.io/en/latest/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;csvkit&lt;/a&gt; suite of command-line tools. It&amp;rsquo;s a wonderful collection of Python programs that can import data into CSV, generate basic column statistics, and use grep and SQL to extract data from a CSV file, amongst other things. This collection is designed to allow you to pipe the output from one as input to the next. Consider 
&lt;a href=&#34;https://csvkit.readthedocs.io/en/latest/tutorial/2_examining_the_data.html#csvsort-order-matters&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this example&lt;/a&gt;. Csvcut is used to extract only certain columns from the file data.csv. Then csvgrep is used to subset to use only the data pertaining to one particular county. Then the data is sorted by the total_cost variable and displayed. I wanted my tool to be compatible with this suite, so if &lt;code&gt;-&lt;/code&gt; is passed as the filename, csv2ds will read the contents of STDIN instead. Changing the above csvkit example by replacing csvlook with my tool will generate the corresponding SAS data set:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;csvcut -c county,item_name,total_cost data.csv | csvgrep -c county -m LANCASTER | csvsort -c total_cost -r | csv2ds -
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;At this point csv2ds is quite simple, but sufficient for my needs. Some minor intervention may be needed to make the data step template work for your data. Informats like DOLLAR are not recognized as numeric and minor edits would need to be made to the produced template.&lt;/p&gt;
&lt;p&gt;Checkout my new tool over on 
&lt;a href=&#34;https://github.com/dmsenter89/csv2ds&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Loading Zillow Housing Data in SAS</title>
      <link>https://dmsenter89.github.io/post/22-08-zillow-data/</link>
      <pubDate>Mon, 01 Aug 2022 17:21:38 -0400</pubDate>
      <guid>https://dmsenter89.github.io/post/22-08-zillow-data/</guid>
      <description>&lt;p&gt;Zillow is a well-known website widely used by those searching for a home or curious to find out
the value of their current home. What you may not know is that Zillow has a dedicated research page.
To make their website work optimally, they churn through tons of data on the American housing market.
They share insights they gleaned via 
&lt;a href=&#34;https://www.zillow.com/research/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;zillow.com/research&lt;/a&gt;. If you
visit their research  website you&amp;rsquo;ll notice they have a data page where you can download some really
cool data sets for your own research. They even have an API with which you can load data directly, but
you&amp;rsquo;ll have to register for access. In this post, we&amp;rsquo;ll look at how to load the CSV files that are
available for direct download into SAS for analysis.&lt;/p&gt;
&lt;p&gt;The CSV files can be downloaded 
&lt;a href=&#34;https://www.zillow.com/research/data/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;. In the example below,
I&amp;rsquo;m working with the Zillow Home Value Index file for all homes, seasonally adjusted at the ZIP code level.
Tha file is fairly large. It has data going from January 2000 through June 2022 in more than 27,000 rows of data
and about 280 columns. Below is an image of the beginning of this file.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;zhvi_data_preview.png&#34; alt=&#34;&#34; title=&#34;The beginning of the of the ZHVI &#39;flagship&#39; data file.&#34;&gt;&lt;/p&gt;
&lt;p&gt;When working with large CSV files, I find it useful to get a feel for it in the CLI with

&lt;a href=&#34;https://csvkit.readthedocs.io/en/latest/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;csvkit&lt;/a&gt;. This is especially important when importing
with a SAS data step, because we need to know the number of columns and their order, amongst other things,
for our code. To get an overview of the total number of columns and their contents, run&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;csvcut -n Zip_zhvi_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The output is fairly long, so you may prefer piping to a pager. I don&amp;rsquo;t need all the different identifiers
in the file, so I&amp;rsquo;m going to exclude those I won&amp;rsquo;t need and put them into a separate, smaller CSV.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# ignore these four columns which I won&#39;t need
csvcut -C RegionID,SizeRank,RegionType,StateName Zip_zhvi_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv &amp;gt; Zip_zhvi_small.csv
# alternatively, also cut down on date columns to only 2022 for debugging 
csvcut -C RegionID,SizeRank,RegionType,StateName,10-273 Zip_zhvi_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv &amp;gt; Zip_zhvi_small.csv
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can also reduce the file size by using &lt;code&gt;csvgrep&lt;/code&gt; to filter any of the columns. For example, if we only wanted
the data for North Carolina we could run &lt;code&gt;csvgrep -c State -m NC&lt;/code&gt; in the pipe.&lt;/p&gt;
&lt;p&gt;For SAS, we need to know the maximum length of string columns so we can allocate the appropriate length to the
corresponding SAS variables. This is easily done with the csvstat tool:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;csvcut -c Metro,City,CountyName Zip_zhvi_small.csv | csvstat --len
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can also specify the list of columns in csvstat directly, but in my experience that tends to be slower.&lt;/p&gt;
&lt;p&gt;Alright, now we have everything we need to start on our DATA step! We start with the attribute statement.
One problem with importing this file is that everyhing is in wide format, with the dates used as headers.
We will get around this shortly. I have seen people use transpose etc for similar problems online, but this
is unnecessary if we feel comfortable with the DATA step. We&amp;rsquo;ll start by naming the identifying columns
just as in the CSV file. For the date columns, we will use a numeric range prefixed by date (&lt;code&gt;date1-date270&lt;/code&gt;).
You can use csvcut to find the exact number of date columns you have. We will also allocate the same number of
columns for the ZHVI values, so we&amp;rsquo;ll need to add a &lt;code&gt;val1-val270&lt;/code&gt;. This and the date variable are temporary
and will be dropped later, in favor of the &lt;code&gt;Date&lt;/code&gt; and &lt;code&gt;ZHVI&lt;/code&gt; variables.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-SAS&#34;&gt;attrib 
    ZIP           informat=best12.    format=z5.
    State         informat=$2.
    City          informat=$30.
    Metro         informat=$42.
    CountyName    informat=$29.
    date1-date270 informat=YYMMDD10.  format=DATE9.
    val1-val270   informat=best16.
    Date                              format=Date9.
    ZHVI                              format=Dollar16.
  ;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we will allocate an array to hold &lt;em&gt;all&lt;/em&gt; of the date and ZHVI values during the processing of each row.
Since the date column won&amp;rsquo;t change, we&amp;rsquo;ll tell SAS to retain its values.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-SAS&#34;&gt;   retain date1-date270;
   array d(270) date1-date270;
   array v(270) val1-val270;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is where the magic happens now. You may not know it, but you are not limited to a single INPUT statement
in a DATA step. We use this and start by reading in only the first row. Because we use an OUTPUT
statement later, this reading of row 1 will be processed, but not saved into the output data set.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-SAS&#34;&gt;if _n_ = 1 then do;
  input ZIP $ State $ City $ Metro $ CountyName $ date1-date270;
  PUT _ALL_; /* if you want to see what that looks like */
end;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With this if clause, the date1 through date270 variables will be populated, and because we used a retain
statement earlier, these values remain available to us during the processing of every other row. You can
probably guess where this is going now: we will process each row, and then OUTPUT one line per date which
we have access to now thanks to our array and the retain statement.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-SAS&#34;&gt;input ZIP $ State $ City $ Metro $ CountyName $ val1-val270;
do i=1 to 270;
  Date  = d(i); /* look up date for column i */
  ZHVI =  v(i); /* use the corresponding i-th value for ZHVI */
  OUTPUT;       /* This output creates one line per date column */
end;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;At the end of your data step, don&amp;rsquo;t forget to&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-SAS&#34;&gt;drop i date1-date270 val1-val270;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;so those variables don&amp;rsquo;t clutter your data set. And that&amp;rsquo;s it! You now
have the data set loaded and available in SAS.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;SAS_data_set.png&#34; alt=&#34;&#34; title=&#34;The beginning of the resulting SAS data set.&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The INDSNAME Option in SAS</title>
      <link>https://dmsenter89.github.io/post/22-04-sas-indsname-option/</link>
      <pubDate>Wed, 20 Apr 2022 11:42:02 -0400</pubDate>
      <guid>https://dmsenter89.github.io/post/22-04-sas-indsname-option/</guid>
      <description>&lt;p&gt;I frequently find myself needing to concatenate data sets but also wanting to be able to distinguish
which row came from which data set originally. Introductory SAS courses tend to teach the &lt;code&gt;in&lt;/code&gt; keyword,
for a workflow similar to this:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-SAS&#34;&gt;data Concat1;
set data1(in = ds0)  
    data2(in = ds1);
if ds0 then source = &amp;quot;data1&amp;quot;;
else if ds1 then source = &amp;quot;data2&amp;quot;;
run;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With more than two input data sets, this can get unwieldy and repetitive. In an old 
&lt;a href=&#34;https://blogs.sas.com/content/iml/2015/08/03/indsname-option.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;blog post&lt;/a&gt;
on Rick Wicklin&amp;rsquo;s DO LOOP, a better method is introduced - the &lt;code&gt;indsname&lt;/code&gt; option. Using this method, the above code looks much nicer:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-SAS&#34;&gt;data Concat2;
set data1-data2 indsname = source;  /* the INDSNAME= option is on the SET statement */
libref = scan(source,1,&#39;.&#39;);        /* extract the libref */
dsname = scan(source,2,&#39;.&#39;);        /* extract the data set name */
run;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As long as your input data sets are reasonably named, you&amp;rsquo;ll now have access to all the information needed.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Multline Bash Variable Replacement</title>
      <link>https://dmsenter89.github.io/post/22-03-multiline-replacement/</link>
      <pubDate>Wed, 16 Mar 2022 09:23:12 -0400</pubDate>
      <guid>https://dmsenter89.github.io/post/22-03-multiline-replacement/</guid>
      <description>&lt;p&gt;I&amp;rsquo;ve recently needed to append several lines of data to a SAS data step that I collected and built
via a shell script. For search-and-replace in bash I typically use sed, but this time I ran into a problem -
sed does not like multiline shell variables. Thanks to Stack, I found a way to accomplish this task using awk instead.&lt;/p&gt;
&lt;p&gt;Suppose you have a file called data.sas with the following contents:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sas&#34;&gt;data person;
   infile datalines delimiter=&#39;,&#39;; 
   input name :$10. dept :$30.;
   datalines4;                      
John,Sales
Mary,Accounting
Theresa,Management
Stewart,HR
;;;;
run;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that I am using a datalines4 statement so that I get an easy to identify target for the substitution.
I want to insert a multiline shell variable before the &lt;code&gt;;;;;&lt;/code&gt; to add my data to this data step. Say I have the
following variable:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;NEWDATA=$(cat &amp;lt;&amp;lt;-END
Will,Compliance
Sidney,Management
END
)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If I try to use sed (&lt;code&gt;sed &amp;quot;s/\;\{4\}/$DATA\n;;;;/&amp;quot; data.sas&lt;/code&gt;) I will get an error about an unterminated s command.
Instead of sed, I can use awk with a variable to achieve the same goal:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;awk -v r=&amp;quot;$NEWDATA\n;;;;&amp;quot; &#39;{gsub(/;{4}/, r)}1&#39; data.sas
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The one downside is that awk does not have an in-place option like sed, and if I try to redirect to the same file
I&amp;rsquo;m reading from I get an empty file out. So you&amp;rsquo;ll have to rename the original file in your processing script to
achieve a similar effect as with the inplace option in sed.&lt;/p&gt;
&lt;p&gt;For additional approaches, see this 
&lt;a href=&#34;https://stackoverflow.com/q/10107459&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;StackOverflow Question&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Cleaning up a Date String with RegEx in SAS</title>
      <link>https://dmsenter89.github.io/post/21-09-sas-regex-date-cleanup/</link>
      <pubDate>Wed, 29 Sep 2021 13:41:36 -0400</pubDate>
      <guid>https://dmsenter89.github.io/post/21-09-sas-regex-date-cleanup/</guid>
      <description>&lt;p&gt;Sometimes we have to deal with manually entered data, which means there is a good chance that the data needs to be cleaned for consistency due to the
inevitable errors that creep in when typing in data, not to speak of any inconsistencies between individuals entering data.&lt;/p&gt;
&lt;p&gt;In my particular case, I was recently dealing with a data set that included
manually calculated ages that had been entered as a complete string
of the number of years, months, and days of an individual. Such a string
is not particularly useful for analysis and I wanted to have the age as
a numeric variable instead. Regular expressions can help out a lot in this
type of situation. In this post, we will look at a few representative examples
of the type of entries I&amp;rsquo;ve encountered and how to read them using RegEx in SAS.&lt;/p&gt;
&lt;h2 id=&#34;lets-look-at-the-data&#34;&gt;Let&amp;rsquo;s Look at the Data&lt;/h2&gt;





  
  











&lt;figure id=&#34;figure-what-were-starting-from&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://dmsenter89.github.io/post/21-09-sas-regex-date-cleanup/RAW_DS_hu83735545411e40d8d73c711ad73aa038_21697_2000x2000_fit_lanczos_2.PNG&#34; data-caption=&#34;What we&amp;amp;rsquo;re starting from.&#34;&gt;


  &lt;img data-src=&#34;https://dmsenter89.github.io/post/21-09-sas-regex-date-cleanup/RAW_DS_hu83735545411e40d8d73c711ad73aa038_21697_2000x2000_fit_lanczos_2.PNG&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;508&#34; height=&#34;250&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    What we&amp;rsquo;re starting from.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;If we look at our sample data, we notice a few things. The data is consistently
ordered from largest to smallest, in the order of year, month, and day.
For some lines, only the year variable is available. In all cases, the string
starts with two digits.&lt;/p&gt;
&lt;p&gt;Separation of the time units is inconsistent; occasionally they are separated
by commas, sometimes by hyphens, and in some cases by spaces alone. The terms
indicating the units are spelled and capitalized inconsistently as well. There
are some abbreviations and occasionally the plural &amp;rsquo;s&#39; in days is wrapped in
parentheses.&lt;/p&gt;
&lt;p&gt;If you want to follow along, you can create the sample data with the
following code:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sas&#34;&gt;data raw;
    infile datalines delimiter = &#39;,&#39; MISSOVER DSD;
    attrib
        ID     informat=best32. format=1.
        STR_AGE informat=$500.   format=$500. label=&#39;Age String&#39;
        VAR1   informat=best32. format=1.;
    input ID STR_AGE $ VAR1;

    datalines;
    1,&amp;quot;62 Years, 5 Months, 8 Days&amp;quot;,1
    2,43 Yrs. -2 Months -4 Day(s), 2
    3,33 years * months 24 days, 1
    4,58,1
    5,&amp;quot;47 Yrs. -11 Months -27 Day(s)&amp;quot;,2
    ;
run;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;the-regex-patterns&#34;&gt;The RegEx Patterns&lt;/h2&gt;
&lt;p&gt;We will use a total of three regex patterns, one for each of the time units:
year, month, day.  SAS uses Pearl regex and the function &lt;code&gt;prxparse&lt;/code&gt; to define
the regex patterns that are supposed to be searched for.&lt;/p&gt;
&lt;p&gt;For the year variable, we need to match the first two digits in our string.
Therefore, the correct call is &lt;code&gt;prxparse(&#39;/^(\d{2}).*/&#39;)&lt;/code&gt;. Note that the
&lt;code&gt;(&lt;/code&gt; and &lt;code&gt;)&lt;/code&gt; delimit the capture group.&lt;/p&gt;
&lt;p&gt;The month and day regex patterns are very similar. For the months, we want to
lazy-match the until we hit between one or two digits followed by
an &amp;rsquo;m&#39; and some number of other characters. We use the &lt;code&gt;i&lt;/code&gt; flag since
we cannot guarantee capitalization: &lt;code&gt;prxparse(&#39;/.*?(\d{1,2}).M.*/i&#39;)&lt;/code&gt;.
The day pattern is nearly identical: &lt;code&gt;prxparse(&#39;/.*?(\d{1,2}).D\D*$/i&#39;)&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;We can extract our matches using the &lt;code&gt;prxposn&lt;/code&gt; function. We use the
&lt;code&gt;prxmatch&lt;/code&gt; function to check if we actually have a match:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sas&#34;&gt;/* match into strings */
if prxmatch(year_rxid, STR_AGE)  then year_dig_str = prxposn(year_rxid,1,STR_AGE);
if prxmatch(month_rxid, STR_AGE) then month_dig_str = prxposn(month_rxid,1,STR_AGE);
if prxmatch(day_rxid, STR_AGE)   then day_dig_str = prxposn(day_rxid,1, STR_AGE);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The extracted strings can then be converted to numeric variables using
the &lt;code&gt;input&lt;/code&gt; function.&lt;/p&gt;
&lt;p&gt;The last step is the calculation of the age from the three components.
Since not all three time units are specified for every row, we cannot use
the standard arithmetic of &lt;code&gt;years + months + days&lt;/code&gt;, because the missing
values would propagate. We need to use the &lt;code&gt;sum&lt;/code&gt; function instead.&lt;/p&gt;
&lt;p&gt;Putting it all together, we get the correct output:&lt;/p&gt;





  
  











&lt;figure id=&#34;figure-the-result&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://dmsenter89.github.io/post/21-09-sas-regex-date-cleanup/FIXED_DS_hu37f587f0a5cd00ab598beb8689b70b5f_34165_2000x2000_fit_lanczos_2.PNG&#34; data-caption=&#34;The Result&#34;&gt;


  &lt;img data-src=&#34;https://dmsenter89.github.io/post/21-09-sas-regex-date-cleanup/FIXED_DS_hu37f587f0a5cd00ab598beb8689b70b5f_34165_2000x2000_fit_lanczos_2.PNG&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;867&#34; height=&#34;251&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    The Result
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h2 id=&#34;complete-code&#34;&gt;Complete Code&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-sas&#34;&gt;data fixed;
    set raw;
    
   /* define the regex patterns */
   year_rxid  = prxparse(&#39;/^(\d{2}).*/&#39;);
   month_rxid = prxparse(&#39;/.*?(\d{1,2}).M.*/i&#39;);
   day_rxid   = prxparse(&#39;/.*?(\d{1,2}).D\D*$/i&#39;);   /* match 2 digits followed by D and non-digit chars  */
  
   /* make sure we have enough space to store the extraction */
   length year_dig_str month_dig_str day_dig_str $4;
   
   /* match into strings */
   /* match into strings */
   if prxmatch(year_rxid, STR_AGE)  then year_dig_str = prxposn(year_rxid,1,STR_AGE);
   if prxmatch(month_rxid, STR_AGE) then month_dig_str = prxposn(month_rxid,1,STR_AGE);
   if prxmatch(day_rxid, STR_AGE)   then day_dig_str = prxposn(day_rxid,1, STR_AGE);
   
   /* use input to convert str -&amp;gt; numeric */
   years  = input(year_dig_str, ? 12.);
   months = input(month_dig_str, ? 12.);
   days   = input(day_dig_str, ? 12.);
   
   /* Use SUM function when calculating age
    to avoid missing values propagating  */
   age = sum(years,months/12,days/365.25);
   
   /* get rid of temporary variables */ 
   drop month_rxid month_dig_str year_rxid year_dig_str day_rxid day_dig_str;
   run;
   
proc print data=fixed; run;
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>From Proc Import to a Data Step with Regex</title>
      <link>https://dmsenter89.github.io/post/21-07-proc-import-to-data-step-with-regex/</link>
      <pubDate>Thu, 29 Jul 2021 08:46:10 -0400</pubDate>
      <guid>https://dmsenter89.github.io/post/21-07-proc-import-to-data-step-with-regex/</guid>
      <description>&lt;p&gt;I find myself needing to import CSV files with a relatively large number of columns. In many cases, &lt;code&gt;proc import&lt;/code&gt; works surprisingly well in giving me what I want. But sometimes, I need to do some work while reading in the file and it would be nice to just use a data step to do so, but I don&amp;rsquo;t want to type it in by hand. That&amp;rsquo;s when a combination of &lt;code&gt;proc import&lt;/code&gt; and some regex substitution can come in handy.&lt;/p&gt;
&lt;p&gt;For the first step, run a &lt;code&gt;proc import&lt;/code&gt;, like this sample code that is provided by SAS Studio when you double click on a CSV file:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sas&#34;&gt;FILENAME REFFILE &#39;/path/to/file/data.csv&#39;;

PROC IMPORT DATAFILE=REFFILE
    DBMS=CSV
    OUT=WORK.IMPORT;
    GETNAMES=YES;
RUN;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you run this code, you will see that SAS generates a complete data step for you. This is what the beginning of one looks like:&lt;/p&gt;





  
  











&lt;figure id=&#34;figure-sample-log-output&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://dmsenter89.github.io/post/21-07-proc-import-to-data-step-with-regex/log_hu417e5750fec5319adb043ca92305efb0_26856_2000x2000_fit_lanczos_2.PNG&#34; data-caption=&#34;Sample log output.&#34;&gt;


  &lt;img data-src=&#34;https://dmsenter89.github.io/post/21-07-proc-import-to-data-step-with-regex/log_hu417e5750fec5319adb043ca92305efb0_26856_2000x2000_fit_lanczos_2.PNG&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;797&#34; height=&#34;461&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Sample log output.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;There will be be two lines for each variable, one giving the &lt;code&gt;informat&lt;/code&gt; and one giving the &lt;code&gt;format&lt;/code&gt; that SAS decided on. This will be followed by an &lt;code&gt;input&lt;/code&gt; statement. You can copy that from the log into a text editor such as VSCode, but unfortunately the line numbering of the LOG will carry over. One convenient way of fixing this is to use regex search-and-replace. Each line starts with a space followed by 1-3 digits, followed by a variable number of spaces until the next word. To capture this I use &lt;code&gt;^\s\d{1,3}\s+&lt;/code&gt; as my search term and replace with nothing. This will left align the whole data step, but this can be adjusted later.&lt;/p&gt;
&lt;p&gt;At this point the data step can be saved as a SAS file or copied back over to the file you are working within SAS Studio, but I like to do one more adjustment. I really like using the &lt;code&gt;attrib&lt;/code&gt; statement, 
&lt;a href=&#34;https://documentation.sas.com/doc/en/pgmsascdc/9.4_3.5/lestmtsref/n1wxb7p9jkxycin16lz2db7idbnt.htm&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;see documentation&lt;/a&gt;, because it allows me to see the informat, format, and label of a variable all in one place. So I use regex to re-arrange my informat statement into the beginnings of an attribute statement. Use the search term &lt;code&gt;informat\s([^\s]+)\s([^\s]+)\s+;&lt;/code&gt; to capture each informat line and create two capture groups - the variable name as group 1 and the informat as group 2. If you use the replace code &lt;code&gt;$1 informat=$2 format=$2&lt;/code&gt;, you will see the beginnings of an attribute statement. In this replacement scheme, each informat matches each format. This is fine for date and character variables, but you may want to adjust the display format for some of your numeric variables.&lt;/p&gt;
&lt;p&gt;To clean this up, get rid of the format lines (you can search for &lt;code&gt;^format.+\n&lt;/code&gt; and replace with an empty replace to delete them), add the &lt;code&gt;attrib&lt;/code&gt; statement below the &lt;code&gt;infile&lt;/code&gt; and make sure to end the block of attributes with a semicolon, and indent your code as desired.&lt;/p&gt;





  
  











&lt;figure id=&#34;figure-sample-data-step-view&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://dmsenter89.github.io/post/21-07-proc-import-to-data-step-with-regex/code_snip_hub5c78044ade6674b35a08b503d783f3d_19917_2000x2000_fit_lanczos_2.PNG&#34; data-caption=&#34;Sample data step view.&#34;&gt;


  &lt;img data-src=&#34;https://dmsenter89.github.io/post/21-07-proc-import-to-data-step-with-regex/code_snip_hub5c78044ade6674b35a08b503d783f3d_19917_2000x2000_fit_lanczos_2.PNG&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;843&#34; height=&#34;190&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Sample data step view.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;And there you have it! The beginning of a nicely formatted data step that you can start to work with.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
